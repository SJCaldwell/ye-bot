{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation using tensor2tensor\n",
    "\n",
    "MODIFIED FROM: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/09_sequence/poetry.ipynb\n",
    "\n",
    "This notebook uses the <a href=\"https://github.com/tensorflow/tensor2tensor\">tensor2tensor</a> library to do from-scratch training of a lyric generating model. Then, the trained model is used to complete new songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this is what this notebook is demonstrating\n",
    "PROBLEM= 'lyric_generation_line_problem'\n",
    "\n",
    "# for bash\n",
    "os.environ['PROBLEM'] = PROBLEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset\n",
    "\n",
    "We are going to train a machine learning model to write poetry given a starting point. We'll give it one line, and it is going to tell us the next line.  So, naturally, we will train it on real poetry. Our feature will be a line of a poem and the label will be next line of that poem.\n",
    "<p>\n",
    "Our training dataset will consist of two files.  The first file will consist of the input lines of poetry and the other file will consist of the corresponding output lines, one output line per input line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/structure/all_merged.txt', 'r') as rawfp,\\\n",
    "  open('data/structure/input.txt', 'w') as infp,\\\n",
    "  open('data/structure/output.txt', 'w') as outfp:\n",
    "    \n",
    "    prev_line = ''\n",
    "    for curr_line in rawfp:\n",
    "        curr_line = curr_line.strip()\n",
    "        # poems break at empty lines, so this ensures we train only\n",
    "        # on lines of the same poem\n",
    "        if len(prev_line) > 0 and len(curr_line) > 0:       \n",
    "            infp.write(prev_line + '\\n')\n",
    "            outfp.write(curr_line + '\\n')\n",
    "        prev_line = curr_line      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> data/structure/all_merged.txt <==\r\n",
      "\r\n",
      "\r\n",
      "[Verse 1]\r\n",
      "(check, yeah)\r\n",
      "We was walking away\r\n",
      "\r\n",
      "==> data/structure/input.txt <==\r\n",
      "[Verse 1]\r\n",
      "(check, yeah)\r\n",
      "We was walking away\r\n",
      "Repeated all we can say\r\n",
      "Depart with a hug\r\n",
      "\r\n",
      "==> data/structure/output.txt <==\r\n",
      "(check, yeah)\r\n",
      "We was walking away\r\n",
      "Repeated all we can say\r\n",
      "Depart with a hug\r\n",
      "And it's a public display\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 data/structure/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to generate the data beforehand -- instead, we can have Tensor2Tensor create the training dataset for us. So, in the code below, I will use only data/structure/raw.txt -- obviously, this allows us to productionize our model better.  Simply keep collecting raw data and generate the training/test data at the time of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up problem\n",
    "The Problem in tensor2tensor is where you specify parameters like the size of your vocabulary and where to get the training data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf lyric_generation\n",
    "mkdir -p lyric_generation/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lyric_generation/trainer/problem.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lyric_generation/trainer/problem.py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.models import transformer\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_encoder\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import generator_utils\n",
    "\n",
    "\n",
    "@registry.register_problem\n",
    "class LyricGenerationLineProblem(text_problems.Text2TextProblem):\n",
    "  \"\"\"Predict next line of poetry from the last line. From Gutenberg texts.\"\"\"\n",
    "\n",
    "  @property\n",
    "  def approx_vocab_size(self):\n",
    "    return 2**13  # ~8k\n",
    "\n",
    "  @property\n",
    "  def is_generate_per_split(self):\n",
    "    # generate_data will NOT shard the data into TRAIN and EVAL for us.\n",
    "    return False\n",
    "\n",
    "  @property\n",
    "  def dataset_splits(self):\n",
    "    \"\"\"Splits of data to produce and number of output shards for each.\"\"\"\n",
    "    # 10% evaluation data\n",
    "    return [{\n",
    "        \"split\": problem.DatasetSplit.TRAIN,\n",
    "        \"shards\": 90,\n",
    "    }, {\n",
    "        \"split\": problem.DatasetSplit.EVAL,\n",
    "        \"shards\": 10,\n",
    "    }]\n",
    "\n",
    "  def generate_samples(self, data_dir, tmp_dir, dataset_split):\n",
    "    with open(\"data/structure/all_merged.txt\", 'r') as rawfp:\n",
    "      prev_line = ''\n",
    "      for curr_line in rawfp:\n",
    "        curr_line = curr_line.strip()\n",
    "        # poems break at empty lines, so this ensures we train only\n",
    "        # on lines of the same poem\n",
    "        if len(prev_line) > 0 and len(curr_line) > 0:       \n",
    "            yield {\n",
    "                \"inputs\": prev_line,\n",
    "                \"targets\": curr_line\n",
    "            }\n",
    "        prev_line = curr_line          \n",
    "\n",
    "\n",
    "# Smaller than the typical translate model, and with more regularization\n",
    "@registry.register_hparams\n",
    "def transformer_lyric_generation():\n",
    "  hparams = transformer.transformer_base()\n",
    "  hparams.num_hidden_layers = 2\n",
    "  hparams.hidden_size = 128\n",
    "  hparams.filter_size = 512\n",
    "  hparams.num_heads = 4\n",
    "  hparams.attention_dropout = 0.6\n",
    "  hparams.layer_prepostprocess_dropout = 0.6\n",
    "  hparams.learning_rate = 0.05\n",
    "  return hparams\n",
    "\n",
    "# hyperparameter tuning ranges\n",
    "@registry.register_ranged_hparams\n",
    "def transformer_lyric_generation_range(rhp):\n",
    "  rhp.set_float(\"learning_rate\", 0.05, 0.25, scale=rhp.LOG_SCALE)\n",
    "  rhp.set_int(\"num_hidden_layers\", 2, 4)\n",
    "  rhp.set_discrete(\"hidden_size\", [128, 256, 512])\n",
    "  rhp.set_float(\"attention_dropout\", 0.4, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lyric_generation/trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lyric_generation/trainer/__init__.py\n",
    "from . import problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lyric_generation/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lyric_generation/setup.py\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "  'tensor2tensor'\n",
    "]\n",
    "\n",
    "setup(\n",
    "    name='lyric_generation',\n",
    "    version='0.1',\n",
    "    author = 'Google',\n",
    "    author_email = 'training-feedback@cloud.google.com',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='Lyric Generation Problem',\n",
    "    requires=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch lyric_generation/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyric_generation\r\n",
      "lyric_generation/__init__.py\r\n",
      "lyric_generation/setup.py\r\n",
      "lyric_generation/trainer\r\n",
      "lyric_generation/trainer/problem.py\r\n",
      "lyric_generation/trainer/__init__.py\r\n"
     ]
    }
   ],
   "source": [
    "!find lyric_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data \n",
    "\n",
    "Our problem (translation) requires the creation of text sequences from the training dataset.  This is done using t2t-datagen and the Problem defined in the previous section.\n",
    "\n",
    "(Ignore any runtime warnings about change in size of numpy.dtype. they are harmless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1544054274.786434889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_problems.py:311) preproc_tokenize_training\n",
      ":::MLPv0.5.0 transformer 1544054296.207107067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/text_problems.py:311) preproc_num_train_examples: 50162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "INFO:tensorflow:Importing user module trainer from path /notebooks/workspace/lyric_generation\n",
      "INFO:tensorflow:Generating problems:\n",
      "    lyric:\n",
      "      * lyric_generation_line_problem\n",
      "INFO:tensorflow:Generating data for lyric_generation_line_problem.\n",
      "INFO:tensorflow:Generating vocab file: data/t2t_data/vocab.lyric_generation_line_problem.8192.subwords\n",
      "INFO:tensorflow:Trying min_count 500\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 1595\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 961\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 988\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 988\n",
      "INFO:tensorflow:Trying min_count 250\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 2631\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 1509\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 1554\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 1547\n",
      "INFO:tensorflow:Trying min_count 125\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 4282\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 2347\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 2417\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 2411\n",
      "INFO:tensorflow:Trying min_count 62\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 6984\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 3717\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 3802\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 3784\n",
      "INFO:tensorflow:Trying min_count 31\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 11257\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 5716\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 5864\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 5842\n",
      "INFO:tensorflow:Trying min_count 15\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 17749\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 8818\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 8981\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 8963\n",
      "INFO:tensorflow:Trying min_count 23\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 13605\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 6870\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 7022\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 7005\n",
      "INFO:tensorflow:Trying min_count 19\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 15305\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 7713\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 7835\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 7816\n",
      "INFO:tensorflow:Trying min_count 17\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 16451\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 8216\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 8373\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 8363\n",
      "INFO:tensorflow:Trying min_count 18\n",
      "INFO:tensorflow:Iteration 0\n",
      "INFO:tensorflow:vocab_size = 16035\n",
      "INFO:tensorflow:Iteration 1\n",
      "INFO:tensorflow:vocab_size = 8030\n",
      "INFO:tensorflow:Iteration 2\n",
      "INFO:tensorflow:vocab_size = 8177\n",
      "INFO:tensorflow:Iteration 3\n",
      "INFO:tensorflow:vocab_size = 8154\n",
      "INFO:tensorflow:Generating case 0.\n",
      "INFO:tensorflow:Generated 50162 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/t2t_data\n",
    "TMP_DIR=$DATA_DIR/tmp\n",
    "rm -rf $DATA_DIR $TMP_DIR\n",
    "mkdir -p $DATA_DIR $TMP_DIR\n",
    "# Generate data\n",
    "t2t-datagen \\\n",
    "  --t2t_usr_dir=lyric_generation/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --tmp_dir=$TMP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyric_generation_line_problem-dev-00000-of-00010\r\n",
      "lyric_generation_line_problem-dev-00001-of-00010\r\n",
      "lyric_generation_line_problem-dev-00002-of-00010\r\n",
      "lyric_generation_line_problem-dev-00003-of-00010\r\n",
      "lyric_generation_line_problem-dev-00004-of-00010\r\n",
      "lyric_generation_line_problem-dev-00005-of-00010\r\n",
      "lyric_generation_line_problem-dev-00006-of-00010\r\n",
      "lyric_generation_line_problem-dev-00007-of-00010\r\n",
      "lyric_generation_line_problem-dev-00008-of-00010\r\n",
      "lyric_generation_line_problem-dev-00009-of-00010\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/t2t_data | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Let's run it locally on a subset of the data to make sure it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following will work only if you are running this notebook on a reasonably powerful machine. Don't be alarmed if your process is killed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1544054473.870245934 (/usr/local/bin/t2t-trainer:28) run_set_random_seed\n",
      ":::MLPv0.5.0 transformer 1544054474.282380104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544054474.285362959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order\n",
      ":::MLPv0.5.0 transformer 1544054474.837483883 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054474.910545111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544054475.214632034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544054475.222029924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544054475.222879887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544054475.223961115 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054475.564250946 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054475.565135956 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054475.565973997 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544054475.858838081 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054475.859700918 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054475.860532045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544054475.945305109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054476.031023979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544054476.038124084 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544054476.039028883 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544054476.040121078 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054476.563261032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054476.564143896 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054476.564939022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544054477.026633024 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054477.027515888 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054477.028352976 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544054477.096872091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054477.225208044 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: \"DEFERRED: 89f7dc23-5563-4a9d-8564-f34e37434dc1\"\n",
      ":::MLPv0.5.0 transformer 1544054477.226016045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000\n",
      ":::MLPv0.5.0 transformer 1544054477.238878965 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: \"Adam\"\n",
      ":::MLPv0.5.0 transformer 1544054477.240504980 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9\n",
      ":::MLPv0.5.0 transformer 1544054477.241278887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997\n",
      ":::MLPv0.5.0 transformer 1544054477.242017031 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09\n",
      ":::MLPv0.5.0 transformer 1544054608.035243034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544054608.580297947 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054608.656307936 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544054608.939097881 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054608.940699100 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544054608.941916943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054608.943171978 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054609.404993057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054609.406287909 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054609.408288956 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054609.701128960 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054609.702393055 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054609.703943968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054609.783389091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054609.875749111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054609.877057076 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544054609.878246069 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054609.879479885 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054610.274298906 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054610.275932074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054610.277244091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054610.710649967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544054610.711908102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544054610.713032007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544054610.771943092 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055197.374464035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544055197.927654028 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055198.003819942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544055198.504578114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055198.505734921 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055198.506807089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055198.507941008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055198.713278055 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055198.714422941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055198.715931892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055199.001698017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055199.002952099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055199.004532099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055199.081059933 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055199.173721075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055199.174976110 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055199.176356077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055199.177484989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055199.569986105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055199.571124077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055199.572499990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055200.022259951 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055200.023749113 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055200.024848938 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055200.084665060 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055208.221249104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544055208.795660019 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055208.873306036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544055209.164324045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.165236950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055209.166074038 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.166896105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055209.384346008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055209.385220051 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055209.386064053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.669981003 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055209.670881033 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055209.672141075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.748821020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055209.838772058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.840285063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055209.841120958 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055209.841907978 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055210.231000900 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055210.232070923 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055210.232877016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055210.660434961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055210.661246061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055210.662014961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055210.717363119 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055218.802678108 (/usr/local/bin/t2t-trainer:28) run_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "INFO:tensorflow:Importing user module trainer from path /notebooks/workspace/lyric_generation\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbb8751a5d0>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 't2t_model', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fbb8751a610>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7fbb8751c578>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 90\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:654: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:947: bucket_by_sequence_length (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.bucket_by_sequence_length(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py:987: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 1970944\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:01:22.901960: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-12-06 00:01:25.198566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:08:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.09GiB\n",
      "2018-12-06 00:01:25.198599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:01:25.459556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:01:25.459591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:01:25.459597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:01:25.459888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into t2t_model/model.ckpt.\n",
      "2018-12-06 00:01:45.175768: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 243 of 512\n",
      "2018-12-06 00:01:55.135512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 488 of 512\n",
      "2018-12-06 00:01:56.061792: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 8.238604, step = 0\n",
      "INFO:tensorflow:global_step/sec: 8.31805\n",
      "INFO:tensorflow:loss = 8.003322, step = 100 (12.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3877\n",
      "INFO:tensorflow:loss = 7.0842195, step = 200 (8.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3616\n",
      "INFO:tensorflow:loss = 6.5354233, step = 300 (8.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3182\n",
      "INFO:tensorflow:loss = 6.0854125, step = 400 (8.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3805\n",
      "INFO:tensorflow:loss = 5.797394, step = 500 (8.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3786\n",
      "INFO:tensorflow:loss = 5.755676, step = 600 (8.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4828\n",
      "INFO:tensorflow:loss = 5.702227, step = 700 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3332\n",
      "INFO:tensorflow:loss = 5.7112603, step = 800 (8.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3497\n",
      "INFO:tensorflow:loss = 5.628837, step = 900 (8.812 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:03:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:03:32.461217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:03:32.461257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:03:32.461265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:03:32.461270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:03:32.461402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:03:39\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 6.673667, metrics-lyric_generation_line_problem/targets/accuracy = 0.10628769, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.22287433, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.003976511, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -6.452792, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.009311945, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.12229272\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: t2t_model/model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 4.79498\n",
      "INFO:tensorflow:loss = 5.621156, step = 1000 (20.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3155\n",
      "INFO:tensorflow:loss = 5.6113334, step = 1100 (8.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3581\n",
      "INFO:tensorflow:loss = 5.559429, step = 1200 (8.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2812\n",
      "INFO:tensorflow:loss = 5.5287814, step = 1300 (8.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3937\n",
      "INFO:tensorflow:loss = 5.490468, step = 1400 (8.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3545\n",
      "INFO:tensorflow:loss = 5.3806624, step = 1500 (8.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4114\n",
      "INFO:tensorflow:loss = 5.1693754, step = 1600 (8.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4555\n",
      "INFO:tensorflow:loss = 5.18793, step = 1700 (8.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.368\n",
      "INFO:tensorflow:loss = 5.057636, step = 1800 (8.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2711\n",
      "INFO:tensorflow:loss = 5.0740466, step = 1900 (8.873 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4351\n",
      "INFO:tensorflow:loss = 5.041339, step = 2000 (9.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.347\n",
      "INFO:tensorflow:loss = 4.9355927, step = 2100 (8.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2969\n",
      "INFO:tensorflow:loss = 4.8412037, step = 2200 (8.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3194\n",
      "INFO:tensorflow:loss = 4.7998257, step = 2300 (8.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3374\n",
      "INFO:tensorflow:loss = 4.697408, step = 2400 (8.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3046\n",
      "INFO:tensorflow:loss = 4.826176, step = 2500 (8.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4688\n",
      "INFO:tensorflow:loss = 4.726938, step = 2600 (8.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2522\n",
      "INFO:tensorflow:loss = 4.6290064, step = 2700 (8.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4586\n",
      "INFO:tensorflow:loss = 4.585014, step = 2800 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4755\n",
      "INFO:tensorflow:loss = 4.700525, step = 2900 (8.714 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2277\n",
      "INFO:tensorflow:loss = 4.50988, step = 3000 (9.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3032\n",
      "INFO:tensorflow:loss = 4.672103, step = 3100 (8.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3988\n",
      "INFO:tensorflow:loss = 4.494076, step = 3200 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2931\n",
      "INFO:tensorflow:loss = 4.522172, step = 3300 (8.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4821\n",
      "INFO:tensorflow:loss = 4.494376, step = 3400 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3059\n",
      "INFO:tensorflow:loss = 4.558405, step = 3500 (8.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3964\n",
      "INFO:tensorflow:loss = 4.4711676, step = 3600 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3444\n",
      "INFO:tensorflow:loss = 4.514842, step = 3700 (8.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3511\n",
      "INFO:tensorflow:loss = 4.2547994, step = 3800 (8.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2911\n",
      "INFO:tensorflow:loss = 4.434685, step = 3900 (8.856 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4268\n",
      "INFO:tensorflow:loss = 4.8796234, step = 4000 (9.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4549\n",
      "INFO:tensorflow:loss = 4.13299, step = 4100 (8.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3035\n",
      "INFO:tensorflow:loss = 5.0204163, step = 4200 (8.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3081\n",
      "INFO:tensorflow:loss = 4.2516937, step = 4300 (8.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3268\n",
      "INFO:tensorflow:loss = 4.433636, step = 4400 (8.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3949\n",
      "INFO:tensorflow:loss = 4.4777656, step = 4500 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3722\n",
      "INFO:tensorflow:loss = 4.3518567, step = 4600 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.375\n",
      "INFO:tensorflow:loss = 4.2715693, step = 4700 (8.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3263\n",
      "INFO:tensorflow:loss = 4.313488, step = 4800 (8.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3248\n",
      "INFO:tensorflow:loss = 4.296247, step = 4900 (8.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4167\n",
      "INFO:tensorflow:loss = 4.3424916, step = 5000 (9.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3536\n",
      "INFO:tensorflow:loss = 4.263448, step = 5100 (8.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.335\n",
      "INFO:tensorflow:loss = 3.913963, step = 5200 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.41\n",
      "INFO:tensorflow:loss = 4.2430077, step = 5300 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4102\n",
      "INFO:tensorflow:loss = 4.2842445, step = 5400 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3962\n",
      "INFO:tensorflow:loss = 4.213351, step = 5500 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.315\n",
      "INFO:tensorflow:loss = 4.102616, step = 5600 (8.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3577\n",
      "INFO:tensorflow:loss = 4.193253, step = 5700 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4637\n",
      "INFO:tensorflow:loss = 4.061924, step = 5800 (8.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.307\n",
      "INFO:tensorflow:loss = 3.9968944, step = 5900 (8.844 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3018\n",
      "INFO:tensorflow:loss = 3.959035, step = 6000 (9.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3479\n",
      "INFO:tensorflow:loss = 4.240381, step = 6100 (8.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3876\n",
      "INFO:tensorflow:loss = 4.241233, step = 6200 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3731\n",
      "INFO:tensorflow:loss = 4.129788, step = 6300 (8.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4544\n",
      "INFO:tensorflow:loss = 4.175607, step = 6400 (8.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2862\n",
      "INFO:tensorflow:loss = 4.2171226, step = 6500 (8.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2793\n",
      "INFO:tensorflow:loss = 4.145051, step = 6600 (8.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3686\n",
      "INFO:tensorflow:loss = 4.259684, step = 6700 (8.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3319\n",
      "INFO:tensorflow:loss = 4.1295137, step = 6800 (8.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3996\n",
      "INFO:tensorflow:loss = 4.032267, step = 6900 (8.772 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5349\n",
      "INFO:tensorflow:loss = 4.1256332, step = 7000 (9.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3953\n",
      "INFO:tensorflow:loss = 4.1162496, step = 7100 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3006\n",
      "INFO:tensorflow:loss = 4.048856, step = 7200 (8.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2492\n",
      "INFO:tensorflow:loss = 4.0574574, step = 7300 (8.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3939\n",
      "INFO:tensorflow:loss = 3.819038, step = 7400 (8.776 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7500 into t2t_model/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:13:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:13:21.210899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:13:21.210944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:13:21.210953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:13:21.210958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:13:21.211102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model/model.ckpt-7500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:13:28\n",
      "INFO:tensorflow:Saving dict for global step 7500: global_step = 7500, loss = 4.82295, metrics-lyric_generation_line_problem/targets/accuracy = 0.24801539, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.43814975, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.035196595, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.7052927, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.059274863, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.25639904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7500: t2t_model/model.ckpt-7500\n",
      "INFO:tensorflow:Loss for final step: 4.18852.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:13:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:13:32.018013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:13:32.018053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:13:32.018061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:13:32.018065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:13:32.018195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model/model.ckpt-7500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:13:38\n",
      "INFO:tensorflow:Saving dict for global step 7500: global_step = 7500, loss = 4.82295, metrics-lyric_generation_line_problem/targets/accuracy = 0.24801539, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.43814975, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.035196595, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.7052927, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.059274863, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.25639904\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7500: t2t_model/model.ckpt-7500\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=data/t2t_data\n",
    "OUTDIR=t2t_model\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --t2t_usr_dir=lyric_generation/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_lyric_generation \\\n",
    "  --output_dir=$OUTDIR --job-dir=$OUTDIR \\\n",
    "  --train_steps=7500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job took about <b>11 minutes</b> for me and ended with these evaluation metrics:\n",
    "<pre>\n",
    "Saving dict for global step 7500: global_step = 7500, loss = 4.82295, metrics-lyric_generation_line_problem/targets/accuracy = 0.24801539, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.43814975, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.035196595, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.7052927, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.059274863, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.25639904\n",
    "</pre>\n",
    "Notice that accuracy_per_sequence is 0 -- Considering that we are asking the NN to be rather creative, that doesn't surprise me. Why am I looking at accuracy_per_sequence and not the other metrics? This is because it is more appropriate for problem we are solving; metrics like Bleu score are better for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "eval\n",
      "events.out.tfevents.1544054481.3877c36ce4b9\n",
      "flags.txt\n",
      "flags_t2t.txt\n",
      "graph.pbtxt\n",
      "hparams.json\n",
      "model.ckpt-0.data-00000-of-00002\n",
      "model.ckpt-0.data-00001-of-00002\n",
      "model.ckpt-0.index\n",
      "model.ckpt-0.meta\n",
      "model.ckpt-1000.data-00000-of-00002\n",
      "model.ckpt-1000.data-00001-of-00002\n",
      "model.ckpt-1000.index\n",
      "model.ckpt-1000.meta\n",
      "model.ckpt-2000.data-00000-of-00002\n",
      "model.ckpt-2000.data-00001-of-00002\n",
      "model.ckpt-2000.index\n",
      "model.ckpt-2000.meta\n",
      "model.ckpt-3000.data-00000-of-00002\n",
      "model.ckpt-3000.data-00001-of-00002\n",
      "model.ckpt-3000.index\n",
      "model.ckpt-3000.meta\n",
      "model.ckpt-4000.data-00000-of-00002\n",
      "model.ckpt-4000.data-00001-of-00002\n",
      "model.ckpt-4000.index\n",
      "model.ckpt-4000.meta\n",
      "model.ckpt-5000.data-00000-of-00002\n",
      "model.ckpt-5000.data-00001-of-00002\n",
      "model.ckpt-5000.index\n",
      "model.ckpt-5000.meta\n",
      "model.ckpt-6000.data-00000-of-00002\n",
      "model.ckpt-6000.data-00001-of-00002\n",
      "model.ckpt-6000.index\n",
      "model.ckpt-6000.meta\n",
      "model.ckpt-7000.data-00000-of-00002\n",
      "model.ckpt-7000.data-00001-of-00002\n",
      "model.ckpt-7000.index\n",
      "model.ckpt-7000.meta\n",
      "model.ckpt-7500.data-00000-of-00002\n",
      "model.ckpt-7500.data-00001-of-00002\n",
      "model.ckpt-7500.index\n",
      "model.ckpt-7500.meta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls t2t_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training longer\n",
    "\n",
    "Let's train for 75,000 steps. Note the change in the last line of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1544055593.587341070 (/usr/local/bin/t2t-trainer:28) run_set_random_seed\n",
      ":::MLPv0.5.0 transformer 1544055593.972029924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544055593.975709915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order\n",
      ":::MLPv0.5.0 transformer 1544055594.517838955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055594.592364073 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544055594.946847916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544055594.954674006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055594.956659079 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544055594.957544088 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055595.352242947 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055595.353110075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055595.353987932 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544055595.653152943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055595.654097080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055595.654994965 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544055595.745637894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055595.834156990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544055595.841439009 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055595.842266083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.6\n",
      ":::MLPv0.5.0 transformer 1544055595.843094110 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055596.385123968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055596.386028051 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055596.387098074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544055596.909332037 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055596.910162926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055596.910991907 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
      ":::MLPv0.5.0 transformer 1544055596.978682995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055597.100280046 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: \"DEFERRED: 6cc6bce2-ea25-4994-b488-68cc01027525\"\n",
      ":::MLPv0.5.0 transformer 1544055597.100955963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000\n",
      ":::MLPv0.5.0 transformer 1544055597.112420082 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: \"Adam\"\n",
      ":::MLPv0.5.0 transformer 1544055597.113102913 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9\n",
      ":::MLPv0.5.0 transformer 1544055597.113737106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997\n",
      ":::MLPv0.5.0 transformer 1544055597.114372969 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09\n",
      ":::MLPv0.5.0 transformer 1544055727.572521925 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544055728.123687983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055728.199412107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544055728.476466894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055728.477721930 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055728.478910923 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055728.480344057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055728.928203106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055728.929439068 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055728.930663109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055729.215621948 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055729.216962099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055729.218151093 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055729.293189049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055729.385235071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055729.386624098 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544055729.388061047 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055729.389156103 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055729.777712107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055729.778991938 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055729.780287981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055730.213768959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544055730.214940071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544055730.216125011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544055730.272805929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056360.585552931 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544056361.049973965 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056361.127247095 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544056361.631381989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056361.632797003 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544056361.633941889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056361.635107994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056361.856869936 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056361.858108044 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056361.859360933 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056362.146141052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056362.147368908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056362.148535013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056362.225378990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056362.317256927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056362.318501949 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544056362.320041895 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056362.321293116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056362.713449955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056362.714668036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056362.716438055 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056363.163158894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056363.164320946 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056363.165436983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056363.223337889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056991.913705111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544056992.481045961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056992.557940006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544056992.838409901 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056992.839637041 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544056992.840799093 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056992.841922998 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056993.043991089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056993.045156002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056993.046272039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056993.537919998 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056993.539303064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056993.540486097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056993.613015890 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056993.696811914 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056993.698050022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544056993.699141026 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056993.700247049 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056994.063751936 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056994.064912081 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056994.066025972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056994.490307093 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544056994.491780996 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544056994.492937088 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544056994.555533886 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057620.321902037 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544057620.866250038 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057620.940530062 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544057621.209031105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.210258007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544057621.211354017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.212508917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057621.408257961 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544057621.409399986 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057621.410643101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.664839029 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544057621.665987968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057621.667108059 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.736283064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057621.818726063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.819905996 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544057621.821027994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057621.822109938 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057622.432056904 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544057622.433264971 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057622.434412956 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057622.872072935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544057622.873337030 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544057622.874526024 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544057622.933681011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058248.822930098 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544058249.375159025 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058249.450304031 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544058249.725644112 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058249.726939917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544058249.728348017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058249.729517937 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058249.930162907 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058249.931369066 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058249.932516098 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058250.204859972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058250.206119061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058250.207360983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058250.283807039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058250.376324892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058250.377578020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544058250.378745079 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058250.379961014 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058251.026252985 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058251.027755976 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058251.029109955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058251.481148005 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058251.482568026 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058251.484103918 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058251.544393063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058879.169589043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544058879.647478104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058879.725609064 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544058880.018481016 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.019901991 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544058880.021095037 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.022213936 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058880.232069969 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058880.233272076 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058880.234381914 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.513777018 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058880.515003920 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058880.516450882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.592153072 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058880.681268930 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.682601929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544058880.684108019 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058880.685271025 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058881.277199984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058881.278356075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058881.279479027 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058881.686393023 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544058881.687870979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544058881.689095974 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544058881.743823051 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059509.310944080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544059509.865834951 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059509.943682909 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544059510.227128983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.228662014 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544059510.229803085 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.230958939 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059510.437510967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544059510.438702106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059510.439904928 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.726703882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544059510.728121042 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059510.729345083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.809962034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059510.900724888 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.902046919 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544059510.903307915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059510.904495955 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059511.301800013 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544059511.303082943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059511.304277897 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059512.016021967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544059512.017215967 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544059512.018338919 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544059512.077162981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060140.401916981 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544060141.086277008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060141.165028095 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544060141.455692053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060141.457036018 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544060141.458214045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060141.459378004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060141.674065113 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060141.675312996 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060141.676503897 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060141.946954966 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060141.948241949 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060141.949425936 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060142.020390034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060142.101901054 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060142.103130102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544060142.104360104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060142.105544090 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060142.459500074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060142.460681915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060142.461834908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060143.115159035 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060143.116449118 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060143.117666006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060143.173031092 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060767.765633106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544060768.369467020 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060768.468563080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544060768.988466978 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060768.989712954 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544060768.991039991 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060768.992197037 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.189434052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060769.190619946 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.191740990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060769.451158047 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060769.452372074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.453488111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060769.523483992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.606055021 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060769.607276917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544060769.608372927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060769.609549999 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.966108084 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060769.967335939 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060769.968508959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060770.378604889 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544060770.380119085 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544060770.381279945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544060770.436475039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061394.649301052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544061395.123642921 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061395.198806047 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544061395.466049910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061395.467276096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544061395.468369007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061395.469512939 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061395.875889063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544061395.877361059 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061395.878519058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061396.131123066 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544061396.132323980 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061396.133430004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061396.203263044 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061396.286418915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061396.288006067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544061396.289141893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061396.290225983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061396.643117905 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544061396.644345999 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061396.645499945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061397.049138069 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544061397.050299883 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544061397.051461935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544061397.105945110 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062021.015127897 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544062021.496896029 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062021.577265024 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544062021.865478992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062021.866905928 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062021.868005991 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062021.869110107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062022.066260099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062022.067459106 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062022.068622112 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062022.327215910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062022.328361034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062022.329468966 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062022.400266886 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062022.482593060 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062022.483829975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062022.484952927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062022.486064911 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062023.068630934 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062023.069780111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062023.070894957 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062023.480632067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062023.481780052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062023.482935905 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062023.538451910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062383.707403898 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544062384.277434111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062384.353019953 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544062384.624464989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062384.625657082 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062384.626781940 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062384.627816916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062384.823918104 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062384.825000048 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062384.826060057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062385.081796885 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062385.082885027 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062385.083982944 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062385.152847052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062385.235045910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062385.236454964 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062385.237509012 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062385.238543034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062385.833893061 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062385.835015059 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062385.836131096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062386.271917105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062386.273111105 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062386.274225950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062386.334050894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062393.611901045 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
      ":::MLPv0.5.0 transformer 1544062394.178642988 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062394.252825975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:228) model_hp_initializer_gain: 1.0\n",
      ":::MLPv0.5.0 transformer 1544062394.520046949 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062394.520888090 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062394.521624088 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062394.522631884 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.096954107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062395.097805023 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.098562002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062395.353039026 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062395.353924036 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.354711056 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062395.422976971 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.502990007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062395.504152060 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062395.504920959 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062395.505650043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.992969990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062395.993818998 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062395.994677067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062396.421473026 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062396.422303915 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062396.423095942 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062396.479686975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062404.051151991 (/usr/local/bin/t2t-trainer:28) run_final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "INFO:tensorflow:Importing user module trainer from path /notebooks/workspace/lyric_generation\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbbae926590>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 't2t_model_full2', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fbbae9265d0>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7fbbae927578>) includes params argument, but params are not passed to Estimator.\n",
      "WARNING:tensorflow:ValidationMonitor only works with --schedule=train_and_evaluate\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-train*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 90\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:654: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:947: bucket_by_sequence_length (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.bucket_by_sequence_length(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'train'\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py:987: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Base learning rate: 2.000000\n",
      "INFO:tensorflow:Trainable Variables Total size: 1970944\n",
      "INFO:tensorflow:Non-trainable variables Total size: 5\n",
      "INFO:tensorflow:Using optimizer Adam\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:20:02.714928: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-12-06 00:20:05.030500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:08:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.09GiB\n",
      "2018-12-06 00:20:05.030533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:20:05.300721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:20:05.300761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:20:05.300769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:20:05.301071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into t2t_model_full2/model.ckpt.\n",
      "2018-12-06 00:20:24.827963: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 239 of 512\n",
      "2018-12-06 00:20:34.806049: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:98] Filling up shuffle buffer (this may take a while): 488 of 512\n",
      "2018-12-06 00:20:35.737254: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:136] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 8.284368, step = 0\n",
      "INFO:tensorflow:global_step/sec: 8.28017\n",
      "INFO:tensorflow:loss = 8.021501, step = 100 (12.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3269\n",
      "INFO:tensorflow:loss = 7.2552447, step = 200 (8.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4479\n",
      "INFO:tensorflow:loss = 6.568366, step = 300 (8.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4309\n",
      "INFO:tensorflow:loss = 6.166166, step = 400 (8.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3408\n",
      "INFO:tensorflow:loss = 5.824607, step = 500 (8.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4514\n",
      "INFO:tensorflow:loss = 5.659233, step = 600 (8.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3779\n",
      "INFO:tensorflow:loss = 5.555775, step = 700 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3453\n",
      "INFO:tensorflow:loss = 5.7423563, step = 800 (8.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4318\n",
      "INFO:tensorflow:loss = 5.7594357, step = 900 (8.747 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:22:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:22:11.906830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:22:11.906870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:22:11.906892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:22:11.906896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:22:11.907019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:22:18\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 6.6686425, metrics-lyric_generation_line_problem/targets/accuracy = 0.109488934, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.22411926, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.0040044426, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -6.4464574, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.008204365, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.12810557\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: t2t_model_full2/model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 4.87169\n",
      "INFO:tensorflow:loss = 5.6384587, step = 1000 (20.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4617\n",
      "INFO:tensorflow:loss = 5.4645996, step = 1100 (8.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.345\n",
      "INFO:tensorflow:loss = 5.4923306, step = 1200 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.442\n",
      "INFO:tensorflow:loss = 5.393851, step = 1300 (8.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3901\n",
      "INFO:tensorflow:loss = 5.4072566, step = 1400 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3455\n",
      "INFO:tensorflow:loss = 5.396032, step = 1500 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3284\n",
      "INFO:tensorflow:loss = 5.2755156, step = 1600 (8.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.403\n",
      "INFO:tensorflow:loss = 5.236181, step = 1700 (8.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3157\n",
      "INFO:tensorflow:loss = 5.183293, step = 1800 (8.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4487\n",
      "INFO:tensorflow:loss = 5.0568285, step = 1900 (8.735 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4729\n",
      "INFO:tensorflow:loss = 4.926453, step = 2000 (9.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3823\n",
      "INFO:tensorflow:loss = 4.829937, step = 2100 (8.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3362\n",
      "INFO:tensorflow:loss = 4.8611703, step = 2200 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3086\n",
      "INFO:tensorflow:loss = 4.9335995, step = 2300 (8.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3871\n",
      "INFO:tensorflow:loss = 4.772021, step = 2400 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3257\n",
      "INFO:tensorflow:loss = 4.7597227, step = 2500 (8.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3972\n",
      "INFO:tensorflow:loss = 4.643886, step = 2600 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2612\n",
      "INFO:tensorflow:loss = 4.731134, step = 2700 (8.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3338\n",
      "INFO:tensorflow:loss = 5.0901537, step = 2800 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4182\n",
      "INFO:tensorflow:loss = 4.6295686, step = 2900 (8.758 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.0861\n",
      "INFO:tensorflow:loss = 4.7789807, step = 3000 (9.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3902\n",
      "INFO:tensorflow:loss = 4.6371326, step = 3100 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3336\n",
      "INFO:tensorflow:loss = 4.6853623, step = 3200 (8.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2796\n",
      "INFO:tensorflow:loss = 4.6755085, step = 3300 (8.867 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2156\n",
      "INFO:tensorflow:loss = 4.462528, step = 3400 (8.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2621\n",
      "INFO:tensorflow:loss = 4.4808846, step = 3500 (8.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3847\n",
      "INFO:tensorflow:loss = 4.4653616, step = 3600 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3455\n",
      "INFO:tensorflow:loss = 4.5214443, step = 3700 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4979\n",
      "INFO:tensorflow:loss = 4.4466357, step = 3800 (8.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3618\n",
      "INFO:tensorflow:loss = 4.4611516, step = 3900 (8.802 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5419\n",
      "INFO:tensorflow:loss = 4.1388507, step = 4000 (9.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2337\n",
      "INFO:tensorflow:loss = 4.403564, step = 4100 (8.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.334\n",
      "INFO:tensorflow:loss = 4.2958145, step = 4200 (8.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4206\n",
      "INFO:tensorflow:loss = 4.280975, step = 4300 (8.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3691\n",
      "INFO:tensorflow:loss = 4.28271, step = 4400 (8.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2796\n",
      "INFO:tensorflow:loss = 4.419817, step = 4500 (8.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2914\n",
      "INFO:tensorflow:loss = 4.466092, step = 4600 (8.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3696\n",
      "INFO:tensorflow:loss = 4.3577027, step = 4700 (8.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4212\n",
      "INFO:tensorflow:loss = 4.2503304, step = 4800 (8.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3378\n",
      "INFO:tensorflow:loss = 4.4495854, step = 4900 (8.820 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5128\n",
      "INFO:tensorflow:loss = 4.215744, step = 5000 (9.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3998\n",
      "INFO:tensorflow:loss = 4.421421, step = 5100 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3528\n",
      "INFO:tensorflow:loss = 4.225442, step = 5200 (8.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.361\n",
      "INFO:tensorflow:loss = 4.3622837, step = 5300 (8.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4186\n",
      "INFO:tensorflow:loss = 4.29806, step = 5400 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4413\n",
      "INFO:tensorflow:loss = 4.108528, step = 5500 (8.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4477\n",
      "INFO:tensorflow:loss = 4.1746497, step = 5600 (8.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.354\n",
      "INFO:tensorflow:loss = 4.1872535, step = 5700 (8.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3787\n",
      "INFO:tensorflow:loss = 4.1516685, step = 5800 (8.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2992\n",
      "INFO:tensorflow:loss = 4.1953363, step = 5900 (8.850 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.263\n",
      "INFO:tensorflow:loss = 3.98926, step = 6000 (9.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3149\n",
      "INFO:tensorflow:loss = 4.2219524, step = 6100 (8.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4276\n",
      "INFO:tensorflow:loss = 4.166172, step = 6200 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2971\n",
      "INFO:tensorflow:loss = 4.126473, step = 6300 (8.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3723\n",
      "INFO:tensorflow:loss = 4.1549973, step = 6400 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3423\n",
      "INFO:tensorflow:loss = 4.1348276, step = 6500 (8.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2453\n",
      "INFO:tensorflow:loss = 4.070519, step = 6600 (8.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2677\n",
      "INFO:tensorflow:loss = 4.1485786, step = 6700 (8.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3733\n",
      "INFO:tensorflow:loss = 4.185755, step = 6800 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3256\n",
      "INFO:tensorflow:loss = 3.9174795, step = 6900 (8.830 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5167\n",
      "INFO:tensorflow:loss = 4.1654015, step = 7000 (9.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3745\n",
      "INFO:tensorflow:loss = 4.1210227, step = 7100 (8.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4718\n",
      "INFO:tensorflow:loss = 4.335606, step = 7200 (8.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.388\n",
      "INFO:tensorflow:loss = 3.9369016, step = 7300 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2912\n",
      "INFO:tensorflow:loss = 4.1020865, step = 7400 (8.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4267\n",
      "INFO:tensorflow:loss = 4.101943, step = 7500 (8.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3754\n",
      "INFO:tensorflow:loss = 4.108809, step = 7600 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2854\n",
      "INFO:tensorflow:loss = 4.1965995, step = 7700 (8.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2728\n",
      "INFO:tensorflow:loss = 4.111662, step = 7800 (8.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4133\n",
      "INFO:tensorflow:loss = 3.972529, step = 7900 (8.761 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:32:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:32:44.364747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:32:44.364788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:32:44.364801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:32:44.364805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:32:44.364936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:32:51\n",
      "INFO:tensorflow:Saving dict for global step 8000: global_step = 8000, loss = 4.813281, metrics-lyric_generation_line_problem/targets/accuracy = 0.24636626, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00019960079, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.44076896, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.031380482, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.692153, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.056285053, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.25252083\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: t2t_model_full2/model.ckpt-8000\n",
      "INFO:tensorflow:global_step/sec: 4.99618\n",
      "INFO:tensorflow:loss = 4.089865, step = 8000 (20.015 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3565\n",
      "INFO:tensorflow:loss = 4.0586524, step = 8100 (8.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3031\n",
      "INFO:tensorflow:loss = 4.168746, step = 8200 (8.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.304\n",
      "INFO:tensorflow:loss = 4.1476593, step = 8300 (8.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3751\n",
      "INFO:tensorflow:loss = 4.1309714, step = 8400 (8.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3283\n",
      "INFO:tensorflow:loss = 4.1410437, step = 8500 (8.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4078\n",
      "INFO:tensorflow:loss = 4.163814, step = 8600 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2539\n",
      "INFO:tensorflow:loss = 3.9629288, step = 8700 (8.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3545\n",
      "INFO:tensorflow:loss = 4.1833506, step = 8800 (8.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4338\n",
      "INFO:tensorflow:loss = 3.9919627, step = 8900 (8.747 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.428\n",
      "INFO:tensorflow:loss = 4.0278, step = 9000 (9.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3465\n",
      "INFO:tensorflow:loss = 4.005827, step = 9100 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4311\n",
      "INFO:tensorflow:loss = 3.990112, step = 9200 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.52\n",
      "INFO:tensorflow:loss = 3.832327, step = 9300 (8.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3802\n",
      "INFO:tensorflow:loss = 4.06423, step = 9400 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4048\n",
      "INFO:tensorflow:loss = 3.9703152, step = 9500 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.351\n",
      "INFO:tensorflow:loss = 3.8950546, step = 9600 (8.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4107\n",
      "INFO:tensorflow:loss = 4.086716, step = 9700 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4362\n",
      "INFO:tensorflow:loss = 4.1102166, step = 9800 (8.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4807\n",
      "INFO:tensorflow:loss = 3.7800598, step = 9900 (8.710 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.506\n",
      "INFO:tensorflow:loss = 3.9461944, step = 10000 (9.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3593\n",
      "INFO:tensorflow:loss = 4.080004, step = 10100 (8.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3672\n",
      "INFO:tensorflow:loss = 4.030365, step = 10200 (8.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3468\n",
      "INFO:tensorflow:loss = 3.9434721, step = 10300 (8.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4127\n",
      "INFO:tensorflow:loss = 3.99492, step = 10400 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3856\n",
      "INFO:tensorflow:loss = 4.0272675, step = 10500 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3773\n",
      "INFO:tensorflow:loss = 3.9558396, step = 10600 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4994\n",
      "INFO:tensorflow:loss = 4.061414, step = 10700 (8.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4001\n",
      "INFO:tensorflow:loss = 4.125872, step = 10800 (8.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4803\n",
      "INFO:tensorflow:loss = 3.9469233, step = 10900 (8.710 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.1986\n",
      "INFO:tensorflow:loss = 4.082802, step = 11000 (9.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.512\n",
      "INFO:tensorflow:loss = 3.8952224, step = 11100 (8.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3627\n",
      "INFO:tensorflow:loss = 4.040675, step = 11200 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3115\n",
      "INFO:tensorflow:loss = 4.081699, step = 11300 (8.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3138\n",
      "INFO:tensorflow:loss = 3.9105356, step = 11400 (8.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4368\n",
      "INFO:tensorflow:loss = 3.3853114, step = 11500 (8.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3366\n",
      "INFO:tensorflow:loss = 3.9461117, step = 11600 (8.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4597\n",
      "INFO:tensorflow:loss = 4.0311055, step = 11700 (8.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3076\n",
      "INFO:tensorflow:loss = 3.9674518, step = 11800 (8.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4995\n",
      "INFO:tensorflow:loss = 4.1119437, step = 11900 (8.696 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4312\n",
      "INFO:tensorflow:loss = 4.0320406, step = 12000 (9.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3568\n",
      "INFO:tensorflow:loss = 4.0162125, step = 12100 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.391\n",
      "INFO:tensorflow:loss = 3.7151241, step = 12200 (8.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2395\n",
      "INFO:tensorflow:loss = 3.918477, step = 12300 (8.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3472\n",
      "INFO:tensorflow:loss = 3.9065442, step = 12400 (8.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.351\n",
      "INFO:tensorflow:loss = 3.8933165, step = 12500 (8.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2906\n",
      "INFO:tensorflow:loss = 3.6728666, step = 12600 (8.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3455\n",
      "INFO:tensorflow:loss = 3.8868682, step = 12700 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4923\n",
      "INFO:tensorflow:loss = 3.8782456, step = 12800 (8.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3511\n",
      "INFO:tensorflow:loss = 3.9416585, step = 12900 (8.809 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3966\n",
      "INFO:tensorflow:loss = 3.867394, step = 13000 (9.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3729\n",
      "INFO:tensorflow:loss = 3.8971615, step = 13100 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3233\n",
      "INFO:tensorflow:loss = 3.9046683, step = 13200 (8.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3712\n",
      "INFO:tensorflow:loss = 3.9666972, step = 13300 (8.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.503\n",
      "INFO:tensorflow:loss = 3.9718795, step = 13400 (8.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4167\n",
      "INFO:tensorflow:loss = 4.2003508, step = 13500 (8.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4279\n",
      "INFO:tensorflow:loss = 4.1567655, step = 13600 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3365\n",
      "INFO:tensorflow:loss = 3.5283692, step = 13700 (8.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4293\n",
      "INFO:tensorflow:loss = 4.1384387, step = 13800 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3645\n",
      "INFO:tensorflow:loss = 3.998198, step = 13900 (8.799 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2297\n",
      "INFO:tensorflow:loss = 4.016006, step = 14000 (9.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3796\n",
      "INFO:tensorflow:loss = 3.8662937, step = 14100 (8.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4417\n",
      "INFO:tensorflow:loss = 4.2101893, step = 14200 (8.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3492\n",
      "INFO:tensorflow:loss = 3.89647, step = 14300 (8.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4571\n",
      "INFO:tensorflow:loss = 3.9019766, step = 14400 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.379\n",
      "INFO:tensorflow:loss = 3.5976539, step = 14500 (8.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3049\n",
      "INFO:tensorflow:loss = 3.9940388, step = 14600 (8.846 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4317\n",
      "INFO:tensorflow:loss = 3.933329, step = 14700 (8.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3485\n",
      "INFO:tensorflow:loss = 4.235042, step = 14800 (8.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3862\n",
      "INFO:tensorflow:loss = 3.6068892, step = 14900 (8.782 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:43:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:43:15.761213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:43:15.761253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:43:15.761261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:43:15.761265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:43:15.761395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:43:22\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, loss = 4.6882534, metrics-lyric_generation_line_problem/targets/accuracy = 0.26096588, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0021956088, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.46342015, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.041044176, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.5462127, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.06427461, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.25618556\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: t2t_model_full2/model.ckpt-15000\n",
      "INFO:tensorflow:global_step/sec: 4.98074\n",
      "INFO:tensorflow:loss = 3.6944518, step = 15000 (20.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4045\n",
      "INFO:tensorflow:loss = 3.9650147, step = 15100 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2929\n",
      "INFO:tensorflow:loss = 3.9071045, step = 15200 (8.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4223\n",
      "INFO:tensorflow:loss = 3.898678, step = 15300 (8.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4123\n",
      "INFO:tensorflow:loss = 4.089395, step = 15400 (8.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3644\n",
      "INFO:tensorflow:loss = 3.8991616, step = 15500 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3621\n",
      "INFO:tensorflow:loss = 3.353268, step = 15600 (8.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2519\n",
      "INFO:tensorflow:loss = 3.8949835, step = 15700 (8.887 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4647\n",
      "INFO:tensorflow:loss = 3.8280928, step = 15800 (8.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.409\n",
      "INFO:tensorflow:loss = 3.9153843, step = 15900 (8.765 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5395\n",
      "INFO:tensorflow:loss = 3.9003823, step = 16000 (9.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4578\n",
      "INFO:tensorflow:loss = 3.849554, step = 16100 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3811\n",
      "INFO:tensorflow:loss = 3.9754877, step = 16200 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.453\n",
      "INFO:tensorflow:loss = 3.905149, step = 16300 (8.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3115\n",
      "INFO:tensorflow:loss = 3.8330996, step = 16400 (8.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2604\n",
      "INFO:tensorflow:loss = 3.9113092, step = 16500 (8.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.44\n",
      "INFO:tensorflow:loss = 3.9598374, step = 16600 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3878\n",
      "INFO:tensorflow:loss = 3.858574, step = 16700 (8.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3684\n",
      "INFO:tensorflow:loss = 4.006238, step = 16800 (8.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4098\n",
      "INFO:tensorflow:loss = 3.9461057, step = 16900 (8.764 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5716\n",
      "INFO:tensorflow:loss = 4.0294504, step = 17000 (9.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2726\n",
      "INFO:tensorflow:loss = 3.6293766, step = 17100 (8.871 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5067\n",
      "INFO:tensorflow:loss = 3.7737262, step = 17200 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3637\n",
      "INFO:tensorflow:loss = 3.9055238, step = 17300 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3764\n",
      "INFO:tensorflow:loss = 3.8862772, step = 17400 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2482\n",
      "INFO:tensorflow:loss = 3.9465032, step = 17500 (8.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5215\n",
      "INFO:tensorflow:loss = 3.903537, step = 17600 (8.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4502\n",
      "INFO:tensorflow:loss = 3.8467586, step = 17700 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3765\n",
      "INFO:tensorflow:loss = 3.9840665, step = 17800 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4086\n",
      "INFO:tensorflow:loss = 3.9760654, step = 17900 (8.766 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4129\n",
      "INFO:tensorflow:loss = 3.971247, step = 18000 (9.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4082\n",
      "INFO:tensorflow:loss = 3.8446708, step = 18100 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4401\n",
      "INFO:tensorflow:loss = 3.738522, step = 18200 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4484\n",
      "INFO:tensorflow:loss = 3.8542056, step = 18300 (8.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4214\n",
      "INFO:tensorflow:loss = 3.5429103, step = 18400 (8.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4003\n",
      "INFO:tensorflow:loss = 3.9321828, step = 18500 (8.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5659\n",
      "INFO:tensorflow:loss = 3.923823, step = 18600 (8.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3811\n",
      "INFO:tensorflow:loss = 3.8677661, step = 18700 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4251\n",
      "INFO:tensorflow:loss = 3.8724353, step = 18800 (8.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4889\n",
      "INFO:tensorflow:loss = 3.9563372, step = 18900 (8.705 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3661\n",
      "INFO:tensorflow:loss = 3.8440926, step = 19000 (9.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4315\n",
      "INFO:tensorflow:loss = 3.7997026, step = 19100 (8.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.436\n",
      "INFO:tensorflow:loss = 3.915041, step = 19200 (8.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4987\n",
      "INFO:tensorflow:loss = 3.6743577, step = 19300 (8.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4854\n",
      "INFO:tensorflow:loss = 3.9599779, step = 19400 (8.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5387\n",
      "INFO:tensorflow:loss = 3.610361, step = 19500 (8.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5406\n",
      "INFO:tensorflow:loss = 3.6252332, step = 19600 (8.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5143\n",
      "INFO:tensorflow:loss = 3.8742738, step = 19700 (8.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5538\n",
      "INFO:tensorflow:loss = 3.8025305, step = 19800 (8.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5772\n",
      "INFO:tensorflow:loss = 3.949036, step = 19900 (8.638 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.599\n",
      "INFO:tensorflow:loss = 3.8199444, step = 20000 (9.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4736\n",
      "INFO:tensorflow:loss = 3.8321667, step = 20100 (8.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4715\n",
      "INFO:tensorflow:loss = 3.7802758, step = 20200 (8.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3666\n",
      "INFO:tensorflow:loss = 3.7395532, step = 20300 (8.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4753\n",
      "INFO:tensorflow:loss = 3.2146945, step = 20400 (8.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4731\n",
      "INFO:tensorflow:loss = 3.9113617, step = 20500 (8.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.328\n",
      "INFO:tensorflow:loss = 3.8893785, step = 20600 (8.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4774\n",
      "INFO:tensorflow:loss = 3.2386663, step = 20700 (8.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3201\n",
      "INFO:tensorflow:loss = 4.511596, step = 20800 (8.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6286\n",
      "INFO:tensorflow:loss = 3.997522, step = 20900 (8.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.369\n",
      "INFO:tensorflow:loss = 3.8163698, step = 21000 (9.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4898\n",
      "INFO:tensorflow:loss = 4.0249457, step = 21100 (8.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4657\n",
      "INFO:tensorflow:loss = 3.855598, step = 21200 (8.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5128\n",
      "INFO:tensorflow:loss = 3.5475469, step = 21300 (8.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4654\n",
      "INFO:tensorflow:loss = 3.757994, step = 21400 (8.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4056\n",
      "INFO:tensorflow:loss = 3.9301693, step = 21500 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3768\n",
      "INFO:tensorflow:loss = 3.4589999, step = 21600 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5391\n",
      "INFO:tensorflow:loss = 3.8580246, step = 21700 (8.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5101\n",
      "INFO:tensorflow:loss = 3.8911886, step = 21800 (8.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3834\n",
      "INFO:tensorflow:loss = 3.9604414, step = 21900 (8.784 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-00:53:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 00:53:43.803675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 00:53:43.803714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 00:53:43.803725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 00:53:43.803730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 00:53:43.803850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-22000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-00:53:50\n",
      "INFO:tensorflow:Saving dict for global step 22000: global_step = 22000, loss = 4.64472, metrics-lyric_generation_line_problem/targets/accuracy = 0.26500785, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0053892215, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.46744597, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.052025307, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.521796, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07228695, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.26709372\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 22000: t2t_model_full2/model.ckpt-22000\n",
      "INFO:tensorflow:global_step/sec: 5.16392\n",
      "INFO:tensorflow:loss = 4.005824, step = 22000 (19.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4685\n",
      "INFO:tensorflow:loss = 3.9124372, step = 22100 (8.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4046\n",
      "INFO:tensorflow:loss = 3.8437953, step = 22200 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5061\n",
      "INFO:tensorflow:loss = 3.7017186, step = 22300 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.505\n",
      "INFO:tensorflow:loss = 3.477659, step = 22400 (8.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.408\n",
      "INFO:tensorflow:loss = 3.8403597, step = 22500 (8.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.558\n",
      "INFO:tensorflow:loss = 3.82559, step = 22600 (8.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5303\n",
      "INFO:tensorflow:loss = 3.8661604, step = 22700 (8.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5051\n",
      "INFO:tensorflow:loss = 3.825315, step = 22800 (8.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.502\n",
      "INFO:tensorflow:loss = 3.8938456, step = 22900 (8.694 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.187\n",
      "INFO:tensorflow:loss = 3.8934805, step = 23000 (9.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4943\n",
      "INFO:tensorflow:loss = 3.8021452, step = 23100 (8.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4784\n",
      "INFO:tensorflow:loss = 3.8238456, step = 23200 (8.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4853\n",
      "INFO:tensorflow:loss = 3.9973161, step = 23300 (8.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5483\n",
      "INFO:tensorflow:loss = 3.8012178, step = 23400 (8.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4497\n",
      "INFO:tensorflow:loss = 3.9283144, step = 23500 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4383\n",
      "INFO:tensorflow:loss = 4.0108376, step = 23600 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4017\n",
      "INFO:tensorflow:loss = 3.8116379, step = 23700 (8.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4224\n",
      "INFO:tensorflow:loss = 3.9267406, step = 23800 (8.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4411\n",
      "INFO:tensorflow:loss = 3.5484736, step = 23900 (8.740 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6059\n",
      "INFO:tensorflow:loss = 3.8620477, step = 24000 (9.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4587\n",
      "INFO:tensorflow:loss = 3.822916, step = 24100 (8.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3239\n",
      "INFO:tensorflow:loss = 4.1583886, step = 24200 (8.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4764\n",
      "INFO:tensorflow:loss = 3.5136075, step = 24300 (8.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5539\n",
      "INFO:tensorflow:loss = 3.9278905, step = 24400 (8.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3798\n",
      "INFO:tensorflow:loss = 3.9396708, step = 24500 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3822\n",
      "INFO:tensorflow:loss = 3.852895, step = 24600 (8.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4933\n",
      "INFO:tensorflow:loss = 3.923492, step = 24700 (8.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3877\n",
      "INFO:tensorflow:loss = 3.7757843, step = 24800 (8.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6571\n",
      "INFO:tensorflow:loss = 3.1618645, step = 24900 (8.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4232\n",
      "INFO:tensorflow:loss = 3.8934448, step = 25000 (9.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4091\n",
      "INFO:tensorflow:loss = 3.8200843, step = 25100 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4782\n",
      "INFO:tensorflow:loss = 3.8557613, step = 25200 (8.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.504\n",
      "INFO:tensorflow:loss = 3.9177845, step = 25300 (8.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3835\n",
      "INFO:tensorflow:loss = 3.9615664, step = 25400 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3514\n",
      "INFO:tensorflow:loss = 3.8181887, step = 25500 (8.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3245\n",
      "INFO:tensorflow:loss = 4.1348615, step = 25600 (8.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.258\n",
      "INFO:tensorflow:loss = 3.5296557, step = 25700 (8.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3415\n",
      "INFO:tensorflow:loss = 3.725872, step = 25800 (8.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4348\n",
      "INFO:tensorflow:loss = 3.8950064, step = 25900 (8.745 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2173\n",
      "INFO:tensorflow:loss = 3.7460184, step = 26000 (9.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4384\n",
      "INFO:tensorflow:loss = 3.8526177, step = 26100 (8.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3274\n",
      "INFO:tensorflow:loss = 3.7420099, step = 26200 (8.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5051\n",
      "INFO:tensorflow:loss = 3.8270507, step = 26300 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4188\n",
      "INFO:tensorflow:loss = 3.8161197, step = 26400 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3723\n",
      "INFO:tensorflow:loss = 3.890609, step = 26500 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4369\n",
      "INFO:tensorflow:loss = 3.8047154, step = 26600 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5062\n",
      "INFO:tensorflow:loss = 3.798024, step = 26700 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.318\n",
      "INFO:tensorflow:loss = 3.8320863, step = 26800 (8.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4404\n",
      "INFO:tensorflow:loss = 3.8570993, step = 26900 (8.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5073\n",
      "INFO:tensorflow:loss = 3.131084, step = 27000 (9.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3025\n",
      "INFO:tensorflow:loss = 3.9110587, step = 27100 (8.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4282\n",
      "INFO:tensorflow:loss = 3.999992, step = 27200 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3957\n",
      "INFO:tensorflow:loss = 3.733085, step = 27300 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.426\n",
      "INFO:tensorflow:loss = 3.509384, step = 27400 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4194\n",
      "INFO:tensorflow:loss = 3.993093, step = 27500 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4698\n",
      "INFO:tensorflow:loss = 3.944336, step = 27600 (8.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4387\n",
      "INFO:tensorflow:loss = 3.7667222, step = 27700 (8.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2419\n",
      "INFO:tensorflow:loss = 3.891219, step = 27800 (8.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4238\n",
      "INFO:tensorflow:loss = 3.8272626, step = 27900 (8.754 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4965\n",
      "INFO:tensorflow:loss = 3.8922994, step = 28000 (9.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4268\n",
      "INFO:tensorflow:loss = 3.7728467, step = 28100 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2145\n",
      "INFO:tensorflow:loss = 4.1734676, step = 28200 (8.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4407\n",
      "INFO:tensorflow:loss = 3.9851532, step = 28300 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.479\n",
      "INFO:tensorflow:loss = 3.8485837, step = 28400 (8.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4782\n",
      "INFO:tensorflow:loss = 3.942883, step = 28500 (8.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3405\n",
      "INFO:tensorflow:loss = 3.9268732, step = 28600 (8.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4101\n",
      "INFO:tensorflow:loss = 3.5769336, step = 28700 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4176\n",
      "INFO:tensorflow:loss = 3.8230734, step = 28800 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4296\n",
      "INFO:tensorflow:loss = 3.1731994, step = 28900 (8.752 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:04:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:04:12.422409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:04:12.422450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:04:12.422459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:04:12.422464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:04:12.422593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-29000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:04:19\n",
      "INFO:tensorflow:Saving dict for global step 29000: global_step = 29000, loss = 4.6346836, metrics-lyric_generation_line_problem/targets/accuracy = 0.2697612, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.007984032, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47231248, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.050525613, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4943385, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07695317, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.2676384\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 29000: t2t_model_full2/model.ckpt-29000\n",
      "INFO:tensorflow:global_step/sec: 4.96687\n",
      "INFO:tensorflow:loss = 3.7078502, step = 29000 (20.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3391\n",
      "INFO:tensorflow:loss = 3.9740906, step = 29100 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3985\n",
      "INFO:tensorflow:loss = 3.9715626, step = 29200 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4083\n",
      "INFO:tensorflow:loss = 3.9417832, step = 29300 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3758\n",
      "INFO:tensorflow:loss = 3.8667872, step = 29400 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2993\n",
      "INFO:tensorflow:loss = 3.958319, step = 29500 (8.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2437\n",
      "INFO:tensorflow:loss = 3.9639084, step = 29600 (8.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.321\n",
      "INFO:tensorflow:loss = 3.9274695, step = 29700 (8.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3158\n",
      "INFO:tensorflow:loss = 3.9073963, step = 29800 (8.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3968\n",
      "INFO:tensorflow:loss = 3.1137528, step = 29900 (8.774 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.1744\n",
      "INFO:tensorflow:loss = 3.7998505, step = 30000 (9.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4369\n",
      "INFO:tensorflow:loss = 3.9033368, step = 30100 (8.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3357\n",
      "INFO:tensorflow:loss = 3.4427526, step = 30200 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3728\n",
      "INFO:tensorflow:loss = 3.3643916, step = 30300 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2869\n",
      "INFO:tensorflow:loss = 3.8552241, step = 30400 (8.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3124\n",
      "INFO:tensorflow:loss = 3.8555338, step = 30500 (8.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3956\n",
      "INFO:tensorflow:loss = 3.8730226, step = 30600 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3271\n",
      "INFO:tensorflow:loss = 3.7053208, step = 30700 (8.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4587\n",
      "INFO:tensorflow:loss = 3.8730838, step = 30800 (8.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3966\n",
      "INFO:tensorflow:loss = 3.85601, step = 30900 (8.774 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5151\n",
      "INFO:tensorflow:loss = 3.8037364, step = 31000 (9.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4496\n",
      "INFO:tensorflow:loss = 3.8833337, step = 31100 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4514\n",
      "INFO:tensorflow:loss = 3.9701445, step = 31200 (8.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3941\n",
      "INFO:tensorflow:loss = 3.9177034, step = 31300 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2665\n",
      "INFO:tensorflow:loss = 3.8910935, step = 31400 (8.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3648\n",
      "INFO:tensorflow:loss = 3.20954, step = 31500 (8.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4241\n",
      "INFO:tensorflow:loss = 3.7063756, step = 31600 (8.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4799\n",
      "INFO:tensorflow:loss = 3.8523138, step = 31700 (8.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3725\n",
      "INFO:tensorflow:loss = 3.825696, step = 31800 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4134\n",
      "INFO:tensorflow:loss = 3.8449624, step = 31900 (8.762 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 32000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4893\n",
      "INFO:tensorflow:loss = 3.8144677, step = 32000 (9.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.427\n",
      "INFO:tensorflow:loss = 3.8279428, step = 32100 (8.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5394\n",
      "INFO:tensorflow:loss = 3.6972573, step = 32200 (8.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4444\n",
      "INFO:tensorflow:loss = 3.7931168, step = 32300 (8.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5139\n",
      "INFO:tensorflow:loss = 3.8201368, step = 32400 (8.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3659\n",
      "INFO:tensorflow:loss = 3.45344, step = 32500 (8.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4555\n",
      "INFO:tensorflow:loss = 3.9934006, step = 32600 (8.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.327\n",
      "INFO:tensorflow:loss = 3.858479, step = 32700 (8.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2818\n",
      "INFO:tensorflow:loss = 3.923296, step = 32800 (8.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.342\n",
      "INFO:tensorflow:loss = 3.458797, step = 32900 (8.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 33000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2934\n",
      "INFO:tensorflow:loss = 3.7917707, step = 33000 (9.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.415\n",
      "INFO:tensorflow:loss = 3.8397615, step = 33100 (8.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3634\n",
      "INFO:tensorflow:loss = 3.6925316, step = 33200 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4679\n",
      "INFO:tensorflow:loss = 3.8609362, step = 33300 (8.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4989\n",
      "INFO:tensorflow:loss = 3.8706734, step = 33400 (8.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3902\n",
      "INFO:tensorflow:loss = 3.7717042, step = 33500 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4529\n",
      "INFO:tensorflow:loss = 3.453589, step = 33600 (8.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.416\n",
      "INFO:tensorflow:loss = 3.8088868, step = 33700 (8.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.41\n",
      "INFO:tensorflow:loss = 3.8374639, step = 33800 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3481\n",
      "INFO:tensorflow:loss = 3.8660886, step = 33900 (8.812 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5342\n",
      "INFO:tensorflow:loss = 3.7209787, step = 34000 (9.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4133\n",
      "INFO:tensorflow:loss = 3.8580165, step = 34100 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3997\n",
      "INFO:tensorflow:loss = 3.951415, step = 34200 (8.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3847\n",
      "INFO:tensorflow:loss = 3.4545772, step = 34300 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4666\n",
      "INFO:tensorflow:loss = 4.1368165, step = 34400 (8.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4559\n",
      "INFO:tensorflow:loss = 3.5448782, step = 34500 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3751\n",
      "INFO:tensorflow:loss = 3.8483064, step = 34600 (8.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4246\n",
      "INFO:tensorflow:loss = 3.8620334, step = 34700 (8.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3894\n",
      "INFO:tensorflow:loss = 3.522313, step = 34800 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4729\n",
      "INFO:tensorflow:loss = 3.9779336, step = 34900 (8.716 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 35000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6043\n",
      "INFO:tensorflow:loss = 3.8893886, step = 35000 (9.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3733\n",
      "INFO:tensorflow:loss = 3.9962656, step = 35100 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5361\n",
      "INFO:tensorflow:loss = 3.9104943, step = 35200 (8.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.407\n",
      "INFO:tensorflow:loss = 3.7407331, step = 35300 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3205\n",
      "INFO:tensorflow:loss = 3.832998, step = 35400 (8.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3269\n",
      "INFO:tensorflow:loss = 3.698269, step = 35500 (8.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5036\n",
      "INFO:tensorflow:loss = 3.8466086, step = 35600 (8.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4421\n",
      "INFO:tensorflow:loss = 3.4888403, step = 35700 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4413\n",
      "INFO:tensorflow:loss = 3.8070369, step = 35800 (8.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4625\n",
      "INFO:tensorflow:loss = 3.4599745, step = 35900 (8.724 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 36000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:14:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:14:42.598954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:14:42.598993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:14:42.599017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:14:42.599022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:14:42.599142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-36000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:14:49\n",
      "INFO:tensorflow:Saving dict for global step 36000: global_step = 36000, loss = 4.6117473, metrics-lyric_generation_line_problem/targets/accuracy = 0.269551, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.0073852297, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47604728, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.055406965, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4862185, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07814482, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.2695073\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36000: t2t_model_full2/model.ckpt-36000\n",
      "INFO:tensorflow:global_step/sec: 5.1137\n",
      "INFO:tensorflow:loss = 3.948699, step = 36000 (19.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4647\n",
      "INFO:tensorflow:loss = 3.6844463, step = 36100 (8.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3515\n",
      "INFO:tensorflow:loss = 3.8767138, step = 36200 (8.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3943\n",
      "INFO:tensorflow:loss = 3.928297, step = 36300 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4721\n",
      "INFO:tensorflow:loss = 3.8394153, step = 36400 (8.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5133\n",
      "INFO:tensorflow:loss = 3.7792242, step = 36500 (8.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.441\n",
      "INFO:tensorflow:loss = 3.9579048, step = 36600 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4094\n",
      "INFO:tensorflow:loss = 4.0240335, step = 36700 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4302\n",
      "INFO:tensorflow:loss = 3.2113714, step = 36800 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4634\n",
      "INFO:tensorflow:loss = 3.8139026, step = 36900 (8.723 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 37000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.1552\n",
      "INFO:tensorflow:loss = 3.9341507, step = 37000 (9.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4367\n",
      "INFO:tensorflow:loss = 3.8141048, step = 37100 (8.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3335\n",
      "INFO:tensorflow:loss = 3.747642, step = 37200 (8.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2816\n",
      "INFO:tensorflow:loss = 3.9504914, step = 37300 (8.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4115\n",
      "INFO:tensorflow:loss = 3.7584355, step = 37400 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1818\n",
      "INFO:tensorflow:loss = 3.8242795, step = 37500 (8.943 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4367\n",
      "INFO:tensorflow:loss = 3.7880635, step = 37600 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4148\n",
      "INFO:tensorflow:loss = 3.867837, step = 37700 (8.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4111\n",
      "INFO:tensorflow:loss = 3.2643945, step = 37800 (8.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5479\n",
      "INFO:tensorflow:loss = 3.7060814, step = 37900 (8.660 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5036\n",
      "INFO:tensorflow:loss = 3.8063214, step = 38000 (9.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3535\n",
      "INFO:tensorflow:loss = 4.547208, step = 38100 (8.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3754\n",
      "INFO:tensorflow:loss = 3.74271, step = 38200 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2989\n",
      "INFO:tensorflow:loss = 3.8901107, step = 38300 (8.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3344\n",
      "INFO:tensorflow:loss = 3.920403, step = 38400 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4588\n",
      "INFO:tensorflow:loss = 3.8313458, step = 38500 (8.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2981\n",
      "INFO:tensorflow:loss = 3.9169765, step = 38600 (8.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3535\n",
      "INFO:tensorflow:loss = 3.8508615, step = 38700 (8.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4379\n",
      "INFO:tensorflow:loss = 3.6982112, step = 38800 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4319\n",
      "INFO:tensorflow:loss = 3.7730517, step = 38900 (8.747 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 39000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4101\n",
      "INFO:tensorflow:loss = 4.2615666, step = 39000 (9.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3393\n",
      "INFO:tensorflow:loss = 3.993705, step = 39100 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5087\n",
      "INFO:tensorflow:loss = 3.8372474, step = 39200 (8.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3899\n",
      "INFO:tensorflow:loss = 3.9826078, step = 39300 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3804\n",
      "INFO:tensorflow:loss = 3.9040272, step = 39400 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4711\n",
      "INFO:tensorflow:loss = 3.8512619, step = 39500 (8.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3846\n",
      "INFO:tensorflow:loss = 3.6690876, step = 39600 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.405\n",
      "INFO:tensorflow:loss = 3.9153008, step = 39700 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4574\n",
      "INFO:tensorflow:loss = 3.1191216, step = 39800 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4406\n",
      "INFO:tensorflow:loss = 3.825976, step = 39900 (8.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.236\n",
      "INFO:tensorflow:loss = 3.842679, step = 40000 (9.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5039\n",
      "INFO:tensorflow:loss = 3.775946, step = 40100 (8.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3567\n",
      "INFO:tensorflow:loss = 3.4949183, step = 40200 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3312\n",
      "INFO:tensorflow:loss = 3.3860726, step = 40300 (8.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4629\n",
      "INFO:tensorflow:loss = 3.6977005, step = 40400 (8.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3601\n",
      "INFO:tensorflow:loss = 3.7643592, step = 40500 (8.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4972\n",
      "INFO:tensorflow:loss = 3.819063, step = 40600 (8.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3586\n",
      "INFO:tensorflow:loss = 3.7900662, step = 40700 (8.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4023\n",
      "INFO:tensorflow:loss = 3.3708677, step = 40800 (8.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2901\n",
      "INFO:tensorflow:loss = 3.8369927, step = 40900 (8.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 41000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5252\n",
      "INFO:tensorflow:loss = 3.3544607, step = 41000 (9.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3637\n",
      "INFO:tensorflow:loss = 3.6875138, step = 41100 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4097\n",
      "INFO:tensorflow:loss = 3.705909, step = 41200 (8.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3391\n",
      "INFO:tensorflow:loss = 4.014399, step = 41300 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3434\n",
      "INFO:tensorflow:loss = 3.9454482, step = 41400 (8.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3439\n",
      "INFO:tensorflow:loss = 3.871431, step = 41500 (8.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5352\n",
      "INFO:tensorflow:loss = 3.8190844, step = 41600 (8.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4061\n",
      "INFO:tensorflow:loss = 3.6609647, step = 41700 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3768\n",
      "INFO:tensorflow:loss = 3.9120722, step = 41800 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4266\n",
      "INFO:tensorflow:loss = 3.562591, step = 41900 (8.752 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 42000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.55\n",
      "INFO:tensorflow:loss = 3.4771488, step = 42000 (9.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4202\n",
      "INFO:tensorflow:loss = 3.7920644, step = 42100 (8.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3389\n",
      "INFO:tensorflow:loss = 3.8287013, step = 42200 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4047\n",
      "INFO:tensorflow:loss = 3.6573288, step = 42300 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3935\n",
      "INFO:tensorflow:loss = 3.7808611, step = 42400 (8.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4059\n",
      "INFO:tensorflow:loss = 3.6650763, step = 42500 (8.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.336\n",
      "INFO:tensorflow:loss = 3.9375885, step = 42600 (8.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3148\n",
      "INFO:tensorflow:loss = 3.7683928, step = 42700 (8.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2603\n",
      "INFO:tensorflow:loss = 3.6427052, step = 42800 (8.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.456\n",
      "INFO:tensorflow:loss = 3.7283356, step = 42900 (8.729 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 43000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:25:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:25:12.970943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:25:12.970996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:25:12.971009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:25:12.971018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:25:12.971165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-43000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:25:19\n",
      "INFO:tensorflow:Saving dict for global step 43000: global_step = 43000, loss = 4.6179094, metrics-lyric_generation_line_problem/targets/accuracy = 0.27241275, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.008782435, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47667783, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.05520156, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.49086, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07658286, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.26942676\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 43000: t2t_model_full2/model.ckpt-43000\n",
      "INFO:tensorflow:global_step/sec: 4.93335\n",
      "INFO:tensorflow:loss = 3.8915954, step = 43000 (20.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.439\n",
      "INFO:tensorflow:loss = 3.4166253, step = 43100 (8.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2802\n",
      "INFO:tensorflow:loss = 3.7679327, step = 43200 (8.865 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2557\n",
      "INFO:tensorflow:loss = 3.8922086, step = 43300 (8.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3897\n",
      "INFO:tensorflow:loss = 3.87852, step = 43400 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3413\n",
      "INFO:tensorflow:loss = 3.8392036, step = 43500 (8.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3089\n",
      "INFO:tensorflow:loss = 3.7727323, step = 43600 (8.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2654\n",
      "INFO:tensorflow:loss = 3.7150056, step = 43700 (8.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3393\n",
      "INFO:tensorflow:loss = 3.8075798, step = 43800 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3529\n",
      "INFO:tensorflow:loss = 3.8042364, step = 43900 (8.808 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 44000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6017\n",
      "INFO:tensorflow:loss = 3.8128805, step = 44000 (9.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3658\n",
      "INFO:tensorflow:loss = 3.9666376, step = 44100 (8.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.43\n",
      "INFO:tensorflow:loss = 3.8464458, step = 44200 (8.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3873\n",
      "INFO:tensorflow:loss = 3.7506523, step = 44300 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3761\n",
      "INFO:tensorflow:loss = 3.7918346, step = 44400 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4084\n",
      "INFO:tensorflow:loss = 3.854432, step = 44500 (8.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3707\n",
      "INFO:tensorflow:loss = 3.4246464, step = 44600 (8.795 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2873\n",
      "INFO:tensorflow:loss = 3.7339375, step = 44700 (8.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3832\n",
      "INFO:tensorflow:loss = 4.3128324, step = 44800 (8.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3912\n",
      "INFO:tensorflow:loss = 3.7954688, step = 44900 (8.779 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 45000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2751\n",
      "INFO:tensorflow:loss = 3.8282719, step = 45000 (9.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3951\n",
      "INFO:tensorflow:loss = 3.6711352, step = 45100 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3626\n",
      "INFO:tensorflow:loss = 3.7961695, step = 45200 (8.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3836\n",
      "INFO:tensorflow:loss = 3.853256, step = 45300 (8.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3994\n",
      "INFO:tensorflow:loss = 3.5724154, step = 45400 (8.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.234\n",
      "INFO:tensorflow:loss = 3.8088932, step = 45500 (8.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3979\n",
      "INFO:tensorflow:loss = 3.8299124, step = 45600 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4777\n",
      "INFO:tensorflow:loss = 3.4775612, step = 45700 (8.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.331\n",
      "INFO:tensorflow:loss = 3.9618697, step = 45800 (8.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3804\n",
      "INFO:tensorflow:loss = 3.8744667, step = 45900 (8.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 46000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3266\n",
      "INFO:tensorflow:loss = 3.7321806, step = 46000 (9.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3421\n",
      "INFO:tensorflow:loss = 3.9605782, step = 46100 (8.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.467\n",
      "INFO:tensorflow:loss = 3.959824, step = 46200 (8.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3741\n",
      "INFO:tensorflow:loss = 3.8365655, step = 46300 (8.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3386\n",
      "INFO:tensorflow:loss = 3.7625155, step = 46400 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3261\n",
      "INFO:tensorflow:loss = 3.431319, step = 46500 (8.829 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4455\n",
      "INFO:tensorflow:loss = 3.8738854, step = 46600 (8.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3909\n",
      "INFO:tensorflow:loss = 3.878581, step = 46700 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3999\n",
      "INFO:tensorflow:loss = 4.0513372, step = 46800 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.327\n",
      "INFO:tensorflow:loss = 3.9314594, step = 46900 (8.827 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 47000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2868\n",
      "INFO:tensorflow:loss = 3.7130828, step = 47000 (9.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3102\n",
      "INFO:tensorflow:loss = 3.7593198, step = 47100 (8.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3785\n",
      "INFO:tensorflow:loss = 3.796716, step = 47200 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4408\n",
      "INFO:tensorflow:loss = 3.7210262, step = 47300 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3985\n",
      "INFO:tensorflow:loss = 3.9647412, step = 47400 (8.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2661\n",
      "INFO:tensorflow:loss = 3.7272146, step = 47500 (8.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4764\n",
      "INFO:tensorflow:loss = 3.836382, step = 47600 (8.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2601\n",
      "INFO:tensorflow:loss = 3.736636, step = 47700 (8.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4689\n",
      "INFO:tensorflow:loss = 3.8083572, step = 47800 (8.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4407\n",
      "INFO:tensorflow:loss = 3.8254662, step = 47900 (8.742 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 48000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4953\n",
      "INFO:tensorflow:loss = 3.789257, step = 48000 (9.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3451\n",
      "INFO:tensorflow:loss = 3.8605142, step = 48100 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3632\n",
      "INFO:tensorflow:loss = 3.675491, step = 48200 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3734\n",
      "INFO:tensorflow:loss = 3.7028692, step = 48300 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4081\n",
      "INFO:tensorflow:loss = 4.155933, step = 48400 (8.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3479\n",
      "INFO:tensorflow:loss = 3.898918, step = 48500 (8.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.479\n",
      "INFO:tensorflow:loss = 3.7949507, step = 48600 (8.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3422\n",
      "INFO:tensorflow:loss = 3.8062427, step = 48700 (8.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.436\n",
      "INFO:tensorflow:loss = 3.8302937, step = 48800 (8.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3812\n",
      "INFO:tensorflow:loss = 3.731064, step = 48900 (8.786 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 49000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6884\n",
      "INFO:tensorflow:loss = 3.7814326, step = 49000 (9.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3946\n",
      "INFO:tensorflow:loss = 3.7727284, step = 49100 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5206\n",
      "INFO:tensorflow:loss = 3.7014692, step = 49200 (8.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4099\n",
      "INFO:tensorflow:loss = 3.8592825, step = 49300 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4341\n",
      "INFO:tensorflow:loss = 3.7528894, step = 49400 (8.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3763\n",
      "INFO:tensorflow:loss = 3.6750898, step = 49500 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4083\n",
      "INFO:tensorflow:loss = 3.5809312, step = 49600 (8.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3397\n",
      "INFO:tensorflow:loss = 3.7442622, step = 49700 (8.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4566\n",
      "INFO:tensorflow:loss = 3.688235, step = 49800 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4879\n",
      "INFO:tensorflow:loss = 3.7265804, step = 49900 (8.705 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 50000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:35:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:35:44.037671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:35:44.037710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:35:44.037719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:35:44.037723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:35:44.037853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-50000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:35:50\n",
      "INFO:tensorflow:Saving dict for global step 50000: global_step = 50000, loss = 4.6117644, metrics-lyric_generation_line_problem/targets/accuracy = 0.27415887, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.009181636, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47777724, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.057203364, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4878554, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07885663, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.2693465\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50000: t2t_model_full2/model.ckpt-50000\n",
      "INFO:tensorflow:global_step/sec: 5.13985\n",
      "INFO:tensorflow:loss = 3.818966, step = 50000 (19.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5185\n",
      "INFO:tensorflow:loss = 3.3810742, step = 50100 (8.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4887\n",
      "INFO:tensorflow:loss = 3.7120593, step = 50200 (8.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5125\n",
      "INFO:tensorflow:loss = 3.839318, step = 50300 (8.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4835\n",
      "INFO:tensorflow:loss = 3.4425094, step = 50400 (8.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4573\n",
      "INFO:tensorflow:loss = 3.689587, step = 50500 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3774\n",
      "INFO:tensorflow:loss = 3.7944868, step = 50600 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5654\n",
      "INFO:tensorflow:loss = 3.4098172, step = 50700 (8.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4862\n",
      "INFO:tensorflow:loss = 3.2458978, step = 50800 (8.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3858\n",
      "INFO:tensorflow:loss = 3.7266932, step = 50900 (8.782 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.4908\n",
      "INFO:tensorflow:loss = 3.8534322, step = 51000 (9.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4862\n",
      "INFO:tensorflow:loss = 3.68776, step = 51100 (8.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4302\n",
      "INFO:tensorflow:loss = 3.397755, step = 51200 (8.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.394\n",
      "INFO:tensorflow:loss = 3.8645942, step = 51300 (8.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5437\n",
      "INFO:tensorflow:loss = 3.7888315, step = 51400 (8.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.516\n",
      "INFO:tensorflow:loss = 3.6739085, step = 51500 (8.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4212\n",
      "INFO:tensorflow:loss = 3.686923, step = 51600 (8.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4794\n",
      "INFO:tensorflow:loss = 3.4146888, step = 51700 (8.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3804\n",
      "INFO:tensorflow:loss = 3.3626978, step = 51800 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4238\n",
      "INFO:tensorflow:loss = 3.7804968, step = 51900 (8.753 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 52000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2391\n",
      "INFO:tensorflow:loss = 3.649196, step = 52000 (9.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5162\n",
      "INFO:tensorflow:loss = 3.7434206, step = 52100 (8.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3759\n",
      "INFO:tensorflow:loss = 3.8319724, step = 52200 (8.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5011\n",
      "INFO:tensorflow:loss = 3.8335643, step = 52300 (8.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.398\n",
      "INFO:tensorflow:loss = 3.7781663, step = 52400 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4349\n",
      "INFO:tensorflow:loss = 3.882123, step = 52500 (8.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4216\n",
      "INFO:tensorflow:loss = 3.8016915, step = 52600 (8.755 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5942\n",
      "INFO:tensorflow:loss = 3.6643937, step = 52700 (8.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3732\n",
      "INFO:tensorflow:loss = 3.6896434, step = 52800 (8.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4592\n",
      "INFO:tensorflow:loss = 3.8008826, step = 52900 (8.726 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 53000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6362\n",
      "INFO:tensorflow:loss = 3.8993964, step = 53000 (9.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4062\n",
      "INFO:tensorflow:loss = 3.9190593, step = 53100 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3973\n",
      "INFO:tensorflow:loss = 3.7562315, step = 53200 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2537\n",
      "INFO:tensorflow:loss = 3.881104, step = 53300 (8.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.485\n",
      "INFO:tensorflow:loss = 3.8946376, step = 53400 (8.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4185\n",
      "INFO:tensorflow:loss = 3.6509786, step = 53500 (8.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4853\n",
      "INFO:tensorflow:loss = 3.8615987, step = 53600 (8.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5267\n",
      "INFO:tensorflow:loss = 3.7915173, step = 53700 (8.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4157\n",
      "INFO:tensorflow:loss = 4.0252876, step = 53800 (8.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3806\n",
      "INFO:tensorflow:loss = 3.726254, step = 53900 (8.787 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 54000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5398\n",
      "INFO:tensorflow:loss = 3.683564, step = 54000 (9.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4039\n",
      "INFO:tensorflow:loss = 3.6161454, step = 54100 (8.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4033\n",
      "INFO:tensorflow:loss = 3.7075686, step = 54200 (8.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.363\n",
      "INFO:tensorflow:loss = 3.854663, step = 54300 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4829\n",
      "INFO:tensorflow:loss = 3.87665, step = 54400 (8.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4185\n",
      "INFO:tensorflow:loss = 3.995114, step = 54500 (8.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4823\n",
      "INFO:tensorflow:loss = 3.3368912, step = 54600 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.406\n",
      "INFO:tensorflow:loss = 3.7475593, step = 54700 (8.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4832\n",
      "INFO:tensorflow:loss = 3.6708286, step = 54800 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4671\n",
      "INFO:tensorflow:loss = 3.5790186, step = 54900 (8.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 55000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3135\n",
      "INFO:tensorflow:loss = 3.451116, step = 55000 (9.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5029\n",
      "INFO:tensorflow:loss = 3.7421396, step = 55100 (8.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4211\n",
      "INFO:tensorflow:loss = 3.7813134, step = 55200 (8.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4962\n",
      "INFO:tensorflow:loss = 3.7435484, step = 55300 (8.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5388\n",
      "INFO:tensorflow:loss = 3.7825775, step = 55400 (8.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3636\n",
      "INFO:tensorflow:loss = 3.913792, step = 55500 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4055\n",
      "INFO:tensorflow:loss = 3.6930482, step = 55600 (8.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4247\n",
      "INFO:tensorflow:loss = 3.9522202, step = 55700 (8.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4352\n",
      "INFO:tensorflow:loss = 3.865095, step = 55800 (8.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5572\n",
      "INFO:tensorflow:loss = 3.6828756, step = 55900 (8.653 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 56000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5075\n",
      "INFO:tensorflow:loss = 3.8236377, step = 56000 (9.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3894\n",
      "INFO:tensorflow:loss = 3.7174995, step = 56100 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4487\n",
      "INFO:tensorflow:loss = 3.688083, step = 56200 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5234\n",
      "INFO:tensorflow:loss = 3.088889, step = 56300 (8.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5294\n",
      "INFO:tensorflow:loss = 3.6877832, step = 56400 (8.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3013\n",
      "INFO:tensorflow:loss = 3.8420935, step = 56500 (8.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4194\n",
      "INFO:tensorflow:loss = 3.8453848, step = 56600 (8.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4378\n",
      "INFO:tensorflow:loss = 3.473221, step = 56700 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3762\n",
      "INFO:tensorflow:loss = 3.7273953, step = 56800 (8.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4773\n",
      "INFO:tensorflow:loss = 3.822937, step = 56900 (8.713 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 57000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:46:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:46:11.594683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:46:11.594722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:46:11.594731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:46:11.594736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:46:11.594867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-57000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:46:17\n",
      "INFO:tensorflow:Saving dict for global step 57000: global_step = 57000, loss = 4.604755, metrics-lyric_generation_line_problem/targets/accuracy = 0.27467623, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00978044, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47847247, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.058718503, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4819655, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.08100153, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.27085513\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 57000: t2t_model_full2/model.ckpt-57000\n",
      "INFO:tensorflow:global_step/sec: 5.08683\n",
      "INFO:tensorflow:loss = 3.787043, step = 57000 (19.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3958\n",
      "INFO:tensorflow:loss = 3.8428876, step = 57100 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4894\n",
      "INFO:tensorflow:loss = 3.8351088, step = 57200 (8.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.526\n",
      "INFO:tensorflow:loss = 3.934854, step = 57300 (8.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4008\n",
      "INFO:tensorflow:loss = 3.759628, step = 57400 (8.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4561\n",
      "INFO:tensorflow:loss = 3.8375952, step = 57500 (8.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4672\n",
      "INFO:tensorflow:loss = 3.8017724, step = 57600 (8.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3927\n",
      "INFO:tensorflow:loss = 3.78522, step = 57700 (8.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5267\n",
      "INFO:tensorflow:loss = 3.5178208, step = 57800 (8.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3671\n",
      "INFO:tensorflow:loss = 3.743211, step = 57900 (8.797 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 58000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5718\n",
      "INFO:tensorflow:loss = 3.7699082, step = 58000 (9.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5519\n",
      "INFO:tensorflow:loss = 3.7654457, step = 58100 (8.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3885\n",
      "INFO:tensorflow:loss = 3.8028731, step = 58200 (8.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2911\n",
      "INFO:tensorflow:loss = 3.8565605, step = 58300 (8.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4551\n",
      "INFO:tensorflow:loss = 3.7943199, step = 58400 (8.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4773\n",
      "INFO:tensorflow:loss = 3.8410957, step = 58500 (8.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5463\n",
      "INFO:tensorflow:loss = 3.746018, step = 58600 (8.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4266\n",
      "INFO:tensorflow:loss = 3.9143195, step = 58700 (8.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4301\n",
      "INFO:tensorflow:loss = 3.6834044, step = 58800 (8.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.542\n",
      "INFO:tensorflow:loss = 3.71258, step = 58900 (8.665 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 59000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.566\n",
      "INFO:tensorflow:loss = 3.797688, step = 59000 (9.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4785\n",
      "INFO:tensorflow:loss = 3.8612957, step = 59100 (8.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4895\n",
      "INFO:tensorflow:loss = 3.2761831, step = 59200 (8.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4896\n",
      "INFO:tensorflow:loss = 4.59972, step = 59300 (8.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.469\n",
      "INFO:tensorflow:loss = 3.8164458, step = 59400 (8.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4342\n",
      "INFO:tensorflow:loss = 3.7502594, step = 59500 (8.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4603\n",
      "INFO:tensorflow:loss = 3.3272655, step = 59600 (8.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4616\n",
      "INFO:tensorflow:loss = 3.923366, step = 59700 (8.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3886\n",
      "INFO:tensorflow:loss = 3.8665695, step = 59800 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3557\n",
      "INFO:tensorflow:loss = 3.6431422, step = 59900 (8.807 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 60000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2235\n",
      "INFO:tensorflow:loss = 3.8051643, step = 60000 (9.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.474\n",
      "INFO:tensorflow:loss = 3.8335066, step = 60100 (8.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4933\n",
      "INFO:tensorflow:loss = 3.8725905, step = 60200 (8.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.462\n",
      "INFO:tensorflow:loss = 3.6820257, step = 60300 (8.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3955\n",
      "INFO:tensorflow:loss = 3.7515912, step = 60400 (8.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.506\n",
      "INFO:tensorflow:loss = 3.7496765, step = 60500 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4752\n",
      "INFO:tensorflow:loss = 3.4683175, step = 60600 (8.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3285\n",
      "INFO:tensorflow:loss = 3.862978, step = 60700 (8.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4559\n",
      "INFO:tensorflow:loss = 3.7608087, step = 60800 (8.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4386\n",
      "INFO:tensorflow:loss = 3.8603299, step = 60900 (8.742 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 61000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6381\n",
      "INFO:tensorflow:loss = 3.8764348, step = 61000 (9.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.537\n",
      "INFO:tensorflow:loss = 3.8586345, step = 61100 (8.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3867\n",
      "INFO:tensorflow:loss = 3.8375027, step = 61200 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4561\n",
      "INFO:tensorflow:loss = 3.5122895, step = 61300 (8.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4597\n",
      "INFO:tensorflow:loss = 3.9033253, step = 61400 (8.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.499\n",
      "INFO:tensorflow:loss = 3.7700226, step = 61500 (8.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5629\n",
      "INFO:tensorflow:loss = 3.74437, step = 61600 (8.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3962\n",
      "INFO:tensorflow:loss = 3.3821952, step = 61700 (8.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3444\n",
      "INFO:tensorflow:loss = 3.759122, step = 61800 (8.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4009\n",
      "INFO:tensorflow:loss = 3.3521664, step = 61900 (8.771 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 62000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3718\n",
      "INFO:tensorflow:loss = 3.7819297, step = 62000 (9.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4803\n",
      "INFO:tensorflow:loss = 3.9582512, step = 62100 (8.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4181\n",
      "INFO:tensorflow:loss = 3.7807896, step = 62200 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3769\n",
      "INFO:tensorflow:loss = 3.7045178, step = 62300 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4863\n",
      "INFO:tensorflow:loss = 3.8006527, step = 62400 (8.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4478\n",
      "INFO:tensorflow:loss = 3.366576, step = 62500 (8.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5362\n",
      "INFO:tensorflow:loss = 3.868809, step = 62600 (8.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3874\n",
      "INFO:tensorflow:loss = 3.6545987, step = 62700 (8.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5087\n",
      "INFO:tensorflow:loss = 3.646969, step = 62800 (8.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3421\n",
      "INFO:tensorflow:loss = 3.8901598, step = 62900 (8.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 63000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5879\n",
      "INFO:tensorflow:loss = 3.6854959, step = 63000 (9.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4315\n",
      "INFO:tensorflow:loss = 3.8740003, step = 63100 (8.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4966\n",
      "INFO:tensorflow:loss = 3.7413294, step = 63200 (8.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4988\n",
      "INFO:tensorflow:loss = 3.8360934, step = 63300 (8.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4139\n",
      "INFO:tensorflow:loss = 3.4375377, step = 63400 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4823\n",
      "INFO:tensorflow:loss = 3.3136053, step = 63500 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5057\n",
      "INFO:tensorflow:loss = 3.8727968, step = 63600 (8.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5254\n",
      "INFO:tensorflow:loss = 3.6942704, step = 63700 (8.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5112\n",
      "INFO:tensorflow:loss = 3.9037874, step = 63800 (8.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5228\n",
      "INFO:tensorflow:loss = 3.7478125, step = 63900 (8.678 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 64000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-01:56:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 01:56:38.265249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 01:56:38.265286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 01:56:38.265309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 01:56:38.265313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 01:56:38.265440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-64000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-01:56:44\n",
      "INFO:tensorflow:Saving dict for global step 64000: global_step = 64000, loss = 4.6205034, metrics-lyric_generation_line_problem/targets/accuracy = 0.27457923, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00998004, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.4777449, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.058127344, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.493367, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07943828, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.27154097\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 64000: t2t_model_full2/model.ckpt-64000\n",
      "INFO:tensorflow:global_step/sec: 5.09267\n",
      "INFO:tensorflow:loss = 3.8090932, step = 64000 (19.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4236\n",
      "INFO:tensorflow:loss = 3.843615, step = 64100 (8.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4889\n",
      "INFO:tensorflow:loss = 3.6334784, step = 64200 (8.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.474\n",
      "INFO:tensorflow:loss = 3.8131676, step = 64300 (8.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.535\n",
      "INFO:tensorflow:loss = 3.5042558, step = 64400 (8.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3642\n",
      "INFO:tensorflow:loss = 3.3792052, step = 64500 (8.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5247\n",
      "INFO:tensorflow:loss = 3.8117769, step = 64600 (8.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3847\n",
      "INFO:tensorflow:loss = 3.7971873, step = 64700 (8.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5183\n",
      "INFO:tensorflow:loss = 3.786763, step = 64800 (8.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5328\n",
      "INFO:tensorflow:loss = 3.7989862, step = 64900 (8.671 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 65000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6016\n",
      "INFO:tensorflow:loss = 3.787516, step = 65000 (9.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4823\n",
      "INFO:tensorflow:loss = 3.3951058, step = 65100 (8.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4774\n",
      "INFO:tensorflow:loss = 3.7825055, step = 65200 (8.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4687\n",
      "INFO:tensorflow:loss = 3.712643, step = 65300 (8.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4536\n",
      "INFO:tensorflow:loss = 3.6602006, step = 65400 (8.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4576\n",
      "INFO:tensorflow:loss = 3.73646, step = 65500 (8.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3369\n",
      "INFO:tensorflow:loss = 3.065082, step = 65600 (8.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3897\n",
      "INFO:tensorflow:loss = 3.725253, step = 65700 (8.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5568\n",
      "INFO:tensorflow:loss = 3.8518019, step = 65800 (8.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6147\n",
      "INFO:tensorflow:loss = 3.8030007, step = 65900 (8.609 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 66000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6695\n",
      "INFO:tensorflow:loss = 3.6512134, step = 66000 (9.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4465\n",
      "INFO:tensorflow:loss = 3.411115, step = 66100 (8.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3222\n",
      "INFO:tensorflow:loss = 3.9340484, step = 66200 (8.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5204\n",
      "INFO:tensorflow:loss = 3.786205, step = 66300 (8.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5044\n",
      "INFO:tensorflow:loss = 3.8897069, step = 66400 (8.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5298\n",
      "INFO:tensorflow:loss = 3.807075, step = 66500 (8.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5108\n",
      "INFO:tensorflow:loss = 3.748801, step = 66600 (8.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4119\n",
      "INFO:tensorflow:loss = 3.3826714, step = 66700 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3809\n",
      "INFO:tensorflow:loss = 3.7192893, step = 66800 (8.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.517\n",
      "INFO:tensorflow:loss = 3.7557807, step = 66900 (8.683 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 67000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3631\n",
      "INFO:tensorflow:loss = 3.7779465, step = 67000 (9.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4184\n",
      "INFO:tensorflow:loss = 3.3273063, step = 67100 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3866\n",
      "INFO:tensorflow:loss = 3.8022292, step = 67200 (8.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.434\n",
      "INFO:tensorflow:loss = 3.853579, step = 67300 (8.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5008\n",
      "INFO:tensorflow:loss = 3.7416937, step = 67400 (8.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5363\n",
      "INFO:tensorflow:loss = 3.8461835, step = 67500 (8.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4945\n",
      "INFO:tensorflow:loss = 3.7629704, step = 67600 (8.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5309\n",
      "INFO:tensorflow:loss = 3.5113242, step = 67700 (8.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4288\n",
      "INFO:tensorflow:loss = 3.7062962, step = 67800 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3307\n",
      "INFO:tensorflow:loss = 3.7440293, step = 67900 (8.826 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 68000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5381\n",
      "INFO:tensorflow:loss = 3.7077246, step = 68000 (9.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5156\n",
      "INFO:tensorflow:loss = 3.688886, step = 68100 (8.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3974\n",
      "INFO:tensorflow:loss = 3.6973693, step = 68200 (8.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4186\n",
      "INFO:tensorflow:loss = 3.861551, step = 68300 (8.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4378\n",
      "INFO:tensorflow:loss = 3.8342404, step = 68400 (8.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4759\n",
      "INFO:tensorflow:loss = 4.0216403, step = 68500 (8.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3612\n",
      "INFO:tensorflow:loss = 3.7273662, step = 68600 (8.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4119\n",
      "INFO:tensorflow:loss = 3.7654672, step = 68700 (8.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4834\n",
      "INFO:tensorflow:loss = 3.8198185, step = 68800 (8.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4682\n",
      "INFO:tensorflow:loss = 3.817537, step = 68900 (8.720 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 69000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6157\n",
      "INFO:tensorflow:loss = 3.7618785, step = 69000 (9.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5546\n",
      "INFO:tensorflow:loss = 3.7837331, step = 69100 (8.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.518\n",
      "INFO:tensorflow:loss = 3.6723132, step = 69200 (8.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4598\n",
      "INFO:tensorflow:loss = 3.7534225, step = 69300 (8.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4284\n",
      "INFO:tensorflow:loss = 3.9280427, step = 69400 (8.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3981\n",
      "INFO:tensorflow:loss = 3.7496629, step = 69500 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.54\n",
      "INFO:tensorflow:loss = 3.9257188, step = 69600 (8.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4837\n",
      "INFO:tensorflow:loss = 3.726724, step = 69700 (8.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4189\n",
      "INFO:tensorflow:loss = 3.813841, step = 69800 (8.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4495\n",
      "INFO:tensorflow:loss = 3.9731836, step = 69900 (8.734 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 70000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.3204\n",
      "INFO:tensorflow:loss = 3.9686677, step = 70000 (9.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.416\n",
      "INFO:tensorflow:loss = 3.75765, step = 70100 (8.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4506\n",
      "INFO:tensorflow:loss = 3.4008534, step = 70200 (8.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.493\n",
      "INFO:tensorflow:loss = 3.8491428, step = 70300 (8.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4147\n",
      "INFO:tensorflow:loss = 3.6351337, step = 70400 (8.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5825\n",
      "INFO:tensorflow:loss = 2.9564147, step = 70500 (8.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4106\n",
      "INFO:tensorflow:loss = 3.378567, step = 70600 (8.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5105\n",
      "INFO:tensorflow:loss = 3.887989, step = 70700 (8.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4839\n",
      "INFO:tensorflow:loss = 3.6542737, step = 70800 (8.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4588\n",
      "INFO:tensorflow:loss = 3.7177427, step = 70900 (8.727 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 71000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-02:07:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 02:07:04.430440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 02:07:04.430479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 02:07:04.430486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 02:07:04.430490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 02:07:04.430622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-71000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-02:07:11\n",
      "INFO:tensorflow:Saving dict for global step 71000: global_step = 71000, loss = 4.634696, metrics-lyric_generation_line_problem/targets/accuracy = 0.27380317, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.011576846, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.47898984, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.058054645, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.499978, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.07843374, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.2651758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 71000: t2t_model_full2/model.ckpt-71000\n",
      "INFO:tensorflow:global_step/sec: 5.11182\n",
      "INFO:tensorflow:loss = 3.7340171, step = 71000 (19.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.447\n",
      "INFO:tensorflow:loss = 3.8685057, step = 71100 (8.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5789\n",
      "INFO:tensorflow:loss = 3.8346229, step = 71200 (8.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5062\n",
      "INFO:tensorflow:loss = 3.7794745, step = 71300 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3569\n",
      "INFO:tensorflow:loss = 3.7457874, step = 71400 (8.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4428\n",
      "INFO:tensorflow:loss = 3.7688491, step = 71500 (8.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5204\n",
      "INFO:tensorflow:loss = 3.7123594, step = 71600 (8.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4406\n",
      "INFO:tensorflow:loss = 3.7176502, step = 71700 (8.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5107\n",
      "INFO:tensorflow:loss = 3.8216798, step = 71800 (8.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4058\n",
      "INFO:tensorflow:loss = 3.7062564, step = 71900 (8.768 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 72000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.2363\n",
      "INFO:tensorflow:loss = 3.765456, step = 72000 (9.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4913\n",
      "INFO:tensorflow:loss = 3.2917778, step = 72100 (8.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5609\n",
      "INFO:tensorflow:loss = 3.830096, step = 72200 (8.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5744\n",
      "INFO:tensorflow:loss = 3.0839202, step = 72300 (8.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4528\n",
      "INFO:tensorflow:loss = 3.673782, step = 72400 (8.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4343\n",
      "INFO:tensorflow:loss = 3.7455292, step = 72500 (8.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5474\n",
      "INFO:tensorflow:loss = 3.798586, step = 72600 (8.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4131\n",
      "INFO:tensorflow:loss = 3.7692313, step = 72700 (8.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4705\n",
      "INFO:tensorflow:loss = 3.7504842, step = 72800 (8.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4624\n",
      "INFO:tensorflow:loss = 3.8959975, step = 72900 (8.724 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 73000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.5667\n",
      "INFO:tensorflow:loss = 3.7446513, step = 73000 (9.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3816\n",
      "INFO:tensorflow:loss = 3.7616036, step = 73100 (8.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4145\n",
      "INFO:tensorflow:loss = 3.877416, step = 73200 (8.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3906\n",
      "INFO:tensorflow:loss = 3.7507854, step = 73300 (8.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4672\n",
      "INFO:tensorflow:loss = 3.963776, step = 73400 (8.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4888\n",
      "INFO:tensorflow:loss = 3.8140306, step = 73500 (8.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4949\n",
      "INFO:tensorflow:loss = 3.8269196, step = 73600 (8.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5061\n",
      "INFO:tensorflow:loss = 3.7869925, step = 73700 (8.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3217\n",
      "INFO:tensorflow:loss = 3.7005866, step = 73800 (8.832 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4639\n",
      "INFO:tensorflow:loss = 3.6262393, step = 73900 (8.723 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 74000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 10.6239\n",
      "INFO:tensorflow:loss = 3.6687734, step = 74000 (9.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4419\n",
      "INFO:tensorflow:loss = 3.9490347, step = 74100 (8.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3982\n",
      "INFO:tensorflow:loss = 3.7200582, step = 74200 (8.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5847\n",
      "INFO:tensorflow:loss = 3.4823716, step = 74300 (8.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.286\n",
      "INFO:tensorflow:loss = 3.618423, step = 74400 (8.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3529\n",
      "INFO:tensorflow:loss = 3.946701, step = 74500 (8.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.433\n",
      "INFO:tensorflow:loss = 3.8938334, step = 74600 (8.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4662\n",
      "INFO:tensorflow:loss = 3.6767025, step = 74700 (8.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3609\n",
      "INFO:tensorflow:loss = 3.7826736, step = 74800 (8.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4516\n",
      "INFO:tensorflow:loss = 4.0299697, step = 74900 (8.732 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 75000 into t2t_model_full2/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-02:13:07\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 02:13:07.217101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 02:13:07.217139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 02:13:07.217146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 02:13:07.217150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 02:13:07.217274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-02:13:13\n",
      "INFO:tensorflow:Saving dict for global step 75000: global_step = 75000, loss = 4.6236544, metrics-lyric_generation_line_problem/targets/accuracy = 0.27194387, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00978044, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.4787635, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.060011823, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4925637, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.08117228, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.27145436\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75000: t2t_model_full2/model.ckpt-75000\n",
      "INFO:tensorflow:Loss for final step: 3.8099263.\n",
      "INFO:tensorflow:Reading data files from data/t2t_data/lyric_generation_line_problem-dev*\n",
      "INFO:tensorflow:partition: 0 num_data_files: 10\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'eval'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_8154_128.bottom\n",
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_8154_128.targets_bottom\n",
      "INFO:tensorflow:Building model body\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_8154_128.top\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-06-02:13:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 02:13:17.508937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 02:13:17.508979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 02:13:17.508989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 02:13:17.508994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 02:13:17.509121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-06-02:13:24\n",
      "INFO:tensorflow:Saving dict for global step 75000: global_step = 75000, loss = 4.6236544, metrics-lyric_generation_line_problem/targets/accuracy = 0.27194387, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00978044, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.4787635, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.060011823, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4925637, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.08117228, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.27145436\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 75000: t2t_model_full2/model.ckpt-75000\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATA_DIR=data/t2t_data\n",
    "OUTDIR=t2t_model_full2\n",
    "rm -rf $OUTDIR\n",
    "t2t-trainer \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --t2t_usr_dir=lyric_generation/trainer \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=transformer \\\n",
    "  --hparams_set=transformer_lyric_generation \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --train_steps=75000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This job took <b>2 hours</b> for me and ended with these metrics:\n",
    "<pre>\n",
    "global_step = 75000, loss = 4.6236544, metrics-lyric_generation_line_problem/targets/accuracy = 0.27194387, metrics-lyric_generation_line_problem/targets/accuracy_per_sequence = 0.00978044, metrics-lyric_generation_line_problem/targets/accuracy_top5 = 0.4787635, metrics-lyric_generation_line_problem/targets/approx_bleu_score = 0.060011823, metrics-lyric_generation_line_problem/targets/neg_log_perplexity = -4.4925637, metrics-lyric_generation_line_problem/targets/rouge_2_fscore = 0.08117228, metrics-lyric_generation_line_problem/targets/rouge_L_fscore = 0.27145436\n",
    "</pre>\n",
    "At least the accuracy per sequence is no longer zero. It is now 0.00978044 ... note that we are using a relatively small dataset (63K lines) and this is *tiny* in the world of natural language problems.\n",
    "<p>\n",
    "In order that you have your expectations set correctly: a high-performing translation model needs 400-million lines of input and takes 1 whole day on a TPU pod!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-predict\n",
    "\n",
    "How will our poetry model do when faced with Kanye's lyrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/test_song.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/test_song.txt\n",
    "[Hook: Kid Cudi]\n",
    "Aint no question if I want it, I need it\n",
    "I can feel it slowly drifting away from me\n",
    "Im on the edge, so why you playing? Im saying\n",
    "I will never ever let you live this down, down, down\n",
    "Not for nothing Ive foreseen it, I dream it\n",
    "I can feel it slowly drifting away from me\n",
    "No more chances if you blow this, you bogus\n",
    "I will never ever let you live this down, down, down\n",
    "[Verse 1: Kanye West]\n",
    "Penitentiary chances, the devil dances\n",
    "And eventually answers to the call of Autumn\n",
    "All of them fallin for the love of ballin\n",
    "Got caught with 30 rocks, the cop look like Alec Baldwin\n",
    "Inter century anthems based off inner city tantrums\n",
    "Based off the way we was branded\n",
    "Face it, Jerome get more time than Brandon\n",
    "And at the airport they check all through my bag\n",
    "And tell me that its random\n",
    "But we stay winning, this week has been a bad massage\n",
    "I need a happy ending and a new beginning\n",
    "And a new fitted, and some job opportunities that's lucrative\n",
    "This the real world, homie, school finished\n",
    "They done stole your dreams, you dunno who did it\n",
    "I treat the cash the way the government treats AIDS\n",
    "I wont be satisfied til all my niggas get it, get it?\n",
    "[Hook: Kid Cudi]\n",
    "Aint no question if I want it, I need it\n",
    "I can feel it slowly drifting away from me\n",
    "Im on the edge, so why you playing? Im saying\n",
    "I will never ever let you live this down, down, down\n",
    "[Verse 2: Kanye West]\n",
    "Is hip hop just a euphemism for a new religion?\n",
    "The soul music of the slaves that the youth is missing\n",
    "This is more than just my road to redemption\n",
    "Malcolm West had the whole nation standing at attention\n",
    "As long as Im in Polo smiling, they think they got me\n",
    "But they would try to crack me if they ever see a black me\n",
    "I thought I chose a field where they couldnt sack me\n",
    "If a nigga ain't shootin' a jump shot, running a track meet\n",
    "But this pimp is, at the top of Mount Olympus\n",
    "Ready for the Worlds game, this is my Olympics\n",
    "We make em say ho cause the game is so pimpish\n",
    "Choke a South Park writer with a fishstick\n",
    "I insisted to get up offa this dick\n",
    "And these drugs, niggas can't resist it\n",
    "Remind me of when they tried to have Ali enlisted\n",
    "If I ever wasn't the greatest nigga, I must have missed it!\n",
    "[Hook: Kid Cudi]\n",
    "Aint no question if I want it, I need it\n",
    "I can feel it slowly drifting away from me\n",
    "Im on the edge, so why you playing? Im saying\n",
    "I will never ever let you live this down, down, down\n",
    "[Verse 3: Kanye West]\n",
    "I need more drinks and less lights\n",
    "And that American Apparel girl in just tights\n",
    "She told the director she tryna get in a school\n",
    "He said take them glasses off and get in the pool\n",
    "Its been a while since I watched the tube\n",
    "Cause like a Crip set, I got way too many blues for any more bad news\n",
    "I was looking at my resume feeling real fresh today\n",
    "They rewrite history, I dont believe in yesterday\n",
    "And whats a black Beatle anyway, a fucking roach?\n",
    "I guess that's why they got me sitting in fucking coach\n",
    "My guy said I need a different approach\n",
    "Cause people is looking at me like Im sniffing coke\n",
    "It's not funny anymore, try different jokes\n",
    "Tell em hug and kiss my ass, x and o\n",
    "And kiss the ring while they at it, do my thing while I got it\n",
    "Play strings for the dramatic ending of that wack shit\n",
    "Act like I ain't had a belt in two classes\n",
    "I ain't got it Im coming after whoever who has it\n",
    "Im coming after whoever. Who has it?\n",
    "You blowin' up, thats good, fantastic\n",
    "That yall, it's like that y'all\n",
    "I dont really give a fuck about it at all\n",
    "Cause the same people that tried to black ball me\n",
    "Forgot about two things, my black balls\n",
    "[Hook: Kid Cudi]\n",
    "Aint no question if I want it, I need it\n",
    "I can feel it slowly drifting away from me\n",
    "Im on the edge, so why you playing? Im saying\n",
    "I will never ever let you live this down, down, down\n",
    "[Verse 4: Raekwon]\n",
    "I done copped Timb's, lived in lenses, kid\n",
    "Armani suits, fresh fruits, Bally boots and Benzes\n",
    "Counting up, smoking, one cuff\n",
    "Live as a red Jag, a Louis bag, grabbing a blunt, fuck it\n",
    "Steam about a hundred and one L's\n",
    "Kites off to jails, buying sweats, running up in Stetson\n",
    "Nigga hat game was special\n",
    "It matched every black pair of Nikes, throwing dice for decimals\n",
    "The older head, bolder head, would train a soldier head\n",
    "Make sure he right in the field, not a soldier dead\n",
    "That meant code red, bent off the black skunk\n",
    "The black dutch, back of the old shed\n",
    "If you cant live, you dying, you give or buy in\n",
    "Keep it real or keep it moving, keep grinding\n",
    "Keep shining, to every young man, this is a plan\n",
    "Learn from others like your brothers Rae and Kanye\n",
    "[Outro: Kid Cudi]\n",
    "Not for nothing I've forseen it, I dream it\n",
    "I can feel it slowly dripping away from me\n",
    "No more chances if you blow this, you bogus\n",
    "I will never ever let you live this down, down, down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write out the odd-numbered lines. We'll compare how close our model can get to the beauty of Rumi's second lines given his first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i can feel it slowly drifting away from me\n",
      "i will never ever let you live this down, down, down\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk 'NR % 2 == 1' data/test_song.txt | tr '[:upper:]' '[:lower:]' | sed \"s/^\\[.*\\]//g\" > data/test_song_leads.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can feel it slowly drifting away from me\n",
      "i will never ever let you live this down, down, down\n",
      "i can feel it slowly drifting away from me\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -3 data/test_song_leads.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1544062447.294462919 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062447.580358982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:231) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062447.581224918 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062447.581873894 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062447.582518101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062447.785921097 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062447.786639929 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062447.787349939 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062448.171170950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062448.172183990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062448.172884941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062448.243597984 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062448.787451982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:231) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062448.788439989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544062448.789318085 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062448.790149927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062449.049484968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062449.050354004 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062449.051182032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062449.501562119 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544062449.502537966 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544062449.503647089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544062449.560589075 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "INFO:tensorflow:Importing user module trainer from path /notebooks/workspace/lyric_generation\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f39cf084b10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 't2t_model_full2', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f39cf084b50>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7f39cdf2c7d0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
      "INFO:tensorflow:Performing decoding from file (data/test_song_leads.txt).\n",
      "INFO:tensorflow:Getting sorted inputs\n",
      "INFO:tensorflow: batch 2\n",
      "INFO:tensorflow:Decoding batch 0\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py:987: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 02:14:10.011079: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-12-06 02:14:12.305281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:08:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.09GiB\n",
      "2018-12-06 02:14:12.305313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 02:14:12.589854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 02:14:12.589895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 02:14:12.589903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 02:14:12.590203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference results INPUT: and kiss the ring while they at it, do my thing while i got it\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: as long as im in polo smiling, they think they got me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: if you cant live, you dying, you give or buy in\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: we make em say ho cause the game is so pimpish\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: i thought i chose a field where they couldnt sack me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: i will never ever let you live this down, down, down\n",
      "INFO:tensorflow:Inference results OUTPUT: Get down, get down, get down\n",
      "INFO:tensorflow:Inference results INPUT: keep shining, to every young man, this is a plan\n",
      "INFO:tensorflow:Inference results OUTPUT: Still shining, still climbing\n",
      "INFO:tensorflow:Inference results INPUT: the older head, bolder head, would train a soldier head\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: cause the same people that tried to black ball me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: act like i ain't had a belt in two classes\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i was looking at my resume feeling real fresh today\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: she told the director she tryna get in a school\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm tryna make it up\n",
      "INFO:tensorflow:Inference results INPUT: remind me of when they tried to have ali enlisted\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: but this pimp is, at the top of mount olympus\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: is hip hop just a euphemism for a new religion?\n",
      "INFO:tensorflow:Inference results OUTPUT: What's the fuck with me?\n",
      "INFO:tensorflow:Inference results INPUT: i treat the cash the way the government treats aids\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly dripping away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: Remind me why I'm a thug nigga?\n",
      "INFO:tensorflow:Inference results INPUT: that meant code red, bent off the black skunk\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly drifting away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: and whats a black beatle anyway, a fucking roach?\n",
      "INFO:tensorflow:Inference results OUTPUT: What's the fuck with me?\n",
      "INFO:tensorflow:Inference results INPUT: its been a while since i watched the tube\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly drifting away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: this is more than just my road to redemption\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly drifting away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i need a happy ending and a new beginning\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: all of them fallin for the love of ballin\n",
      "INFO:tensorflow:Inference results OUTPUT: From the smog and the smoke\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly drifting away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Decoding batch 1\n",
      "INFO:tensorflow:Inference results INPUT: i can feel it slowly drifting away from me\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i done copped timb's, lived in lenses, kid\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: my guy said i need a different approach\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i insisted to get up offa this dick\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: face it, jerome get more time than brandon\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: inter century anthems based off inner city tantrums\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Inference results INPUT: steam about a hundred and one l's\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: im coming after whoever. who has it?\n",
      "INFO:tensorflow:Inference results OUTPUT:    SASHA: It's why I'm saying\n",
      "INFO:tensorflow:Inference results INPUT: it's not funny anymore, try different jokes\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: i need more drinks and less lights\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: this the real world, homie, school finished\n",
      "INFO:tensorflow:Inference results OUTPUT: I'm a nigga, I'm a nigga\n",
      "INFO:tensorflow:Inference results INPUT: that yall, it's like that y'all\n",
      "INFO:tensorflow:Inference results OUTPUT: Came up, that's all me, that's all me\n",
      "INFO:tensorflow:Inference results INPUT: and tell me that its random\n",
      "INFO:tensorflow:Inference results OUTPUT: Somewhere far as a woman so heartless\n",
      "INFO:tensorflow:Inference results INPUT: nigga hat game was special\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm tryna find some shit\n",
      "INFO:tensorflow:Inference results INPUT: counting up, smoking, one cuff\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the same thing\n",
      "INFO:tensorflow:Inference results INPUT: penitentiary chances, the devil dances\n",
      "INFO:tensorflow:Inference results OUTPUT: And I'm a lot of the world\n",
      "INFO:tensorflow:Elapsed Time: 8.02582\n",
      "INFO:tensorflow:Averaged Single Token Generation Time: 0.0034592 (time 7.9699144 count 2304)\n",
      "INFO:tensorflow:Writing decodes into data/test_song_leads.txt.transformer.transformer_lyric_generation.lyric_generation_line_problem.beam4.alpha0.6.decodes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# same as the above training job ...\n",
    "DATA_DIR=data/t2t_data\n",
    "OUTDIR=t2t_model_full2\n",
    "MODEL=transformer\n",
    "HPARAMS=transformer_lyric_generation\n",
    "\n",
    "# the file with the input lines\n",
    "DECODE_FILE=data/test_song_leads.txt\n",
    "\n",
    "BEAM_SIZE=4\n",
    "ALPHA=0.6\n",
    "\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=transformer_lyric_generation \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --t2t_usr_dir=lyric_generation/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note </b> if you get an error about \"AttributeError: 'HParams' object has no attribute 'problems'\" please <b>Reset Session</b>, run the cell that defines the PROBLEM and run the above cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And I'm a lot of the same thing\n",
      "Get down, get down, get down\n",
      "And I'm a lot of the same thing\n",
      "Get down, get down, get down\n",
      "And I'm a lot of the world\n",
      "From the smog and the smoke\n",
      "And I'm a lot of the world\n",
      "And I'm a lot of the world\n",
      "Somewhere far as a woman so heartless\n",
      "And I'm a lot of the same thing\n",
      "I'm a nigga, I'm a nigga\n",
      "And I'm a lot of the world\n",
      "And I'm a lot of the same thing\n",
      "Get down, get down, get down\n",
      "What's the fuck with me?\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the world\n",
      "And I'm a lot of the world\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the world\n",
      "And I'm a lot of the same thing\n",
      "Get down, get down, get down\n",
      "And I'm a lot of the same thing\n",
      "And I'm tryna make it up\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the world\n",
      "What's the fuck with me?\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "   SASHA: It's why I'm saying\n",
      "Came up, that's all me, that's all me\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "Get down, get down, get down\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm tryna find some shit\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the same thing\n",
      "And I'm a lot of the world\n",
      "Still shining, still climbing\n",
      "Remind me why I'm a thug nigga?\n",
      "Get down, get down, get down\n"
     ]
    }
   ],
   "source": [
    "%%bash  \n",
    "DECODE_FILE=data/test_song_leads.txt\n",
    "cat ${DECODE_FILE}.*.decodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try creating an entire verse from scratch. We'll have to give the model a seed line to start off with. Let's try \"data science students got bars for days\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data/song_from_scratch.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/song_from_scratch.txt\n",
    "yo, who dat boy? who him is?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 11 data/song_from_scratch.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the below cell as many times as you wish to generate line after line, where each generated line will be used as the next input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLPv0.5.0 transformer 1544077005.564482927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 8154, \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077005.834992886 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:231) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077005.835800886 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544077005.836397886 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077005.836987019 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077006.026851892 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544077006.027800083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077006.028517008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077006.392316103 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544077006.392997980 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077006.393652916 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077006.462570906 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077007.013355017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:231) model_hp_layer_postprocess_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077007.014352083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
      ":::MLPv0.5.0 transformer 1544077007.015165091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077007.016016006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077007.290822983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544077007.291819096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077007.292666912 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077007.773060083 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
      ":::MLPv0.5.0 transformer 1544077007.773941040 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
      ":::MLPv0.5.0 transformer 1544077007.774890900 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
      ":::MLPv0.5.0 transformer 1544077007.835640907 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_max_len_seq.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._max_len_seq_inner import _max_len_seq_inner\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_upfirdn.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._upfirdn_apply import _output_len, _apply\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/spectral.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._spectral import _lombscargle\n",
      "/usr/local/lib/python2.7/dist-packages/scipy/signal/_peak_finding.py:13: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._peak_finding_utils import (_argmaxima1d, _select_by_peak_distance,\n",
      "INFO:tensorflow:Importing user module trainer from path /notebooks/workspace/lyric_generation\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Configuring DataParallelism to replicate the model.\n",
      "INFO:tensorflow:schedule=continuous_train_and_eval\n",
      "INFO:tensorflow:worker_gpu=1\n",
      "INFO:tensorflow:sync=False\n",
      "WARNING:tensorflow:Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
      "INFO:tensorflow:datashard_devices: ['gpu:0']\n",
      "INFO:tensorflow:caching_devices: None\n",
      "INFO:tensorflow:ps_devices: ['gpu:0']\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98e5fe0b10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.95\n",
      "}\n",
      "allow_soft_placement: true\n",
      "graph_options {\n",
      "  optimizer_options {\n",
      "    global_jit_level: OFF\n",
      "  }\n",
      "}\n",
      ", '_model_dir': 't2t_model_full2', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f98e5fe0b50>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function wrapping_model_fn at 0x7f98e4e887d0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:decode_hp.batch_size not specified; default=32\n",
      "INFO:tensorflow:Performing decoding from file (data/input_line_tmp.txt).\n",
      "INFO:tensorflow:Getting sorted inputs\n",
      "INFO:tensorflow: batch 1\n",
      "INFO:tensorflow:Decoding batch 0\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n",
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n",
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n",
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n",
      "INFO:tensorflow:Beam Decoding with beam size 4\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/function.py:987: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-12-06 06:16:48.286633: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-12-06 06:16:50.607500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: Tesla K40c major: 3 minor: 5 memoryClockRate(GHz): 0.745\n",
      "pciBusID: 0000:08:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.09GiB\n",
      "2018-12-06 06:16:50.607532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2018-12-06 06:16:50.845339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-06 06:16:50.845383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2018-12-06 06:16:50.845390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2018-12-06 06:16:50.845663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K40c, pci bus id: 0000:08:00.0, compute capability: 3.5)\n",
      "INFO:tensorflow:Restoring parameters from t2t_model_full2/model.ckpt-75000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference results INPUT: Gangstas, softer than a gwaan, softer than a gwaan\n",
      "INFO:tensorflow:Inference results OUTPUT: Gangstas, softer than a gwaan, softer than a gwaan\n",
      "INFO:tensorflow:Elapsed Time: 7.43100\n",
      "INFO:tensorflow:Averaged Single Token Generation Time: 0.1719347 (time 7.3931921 count 43)\n",
      "INFO:tensorflow:Writing decodes into data/input_line_tmp.txt.transformer.transformer_lyric_generation.lyric_generation_line_problem.beam4.alpha0.6.decodes\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Destroy temp file\n",
    "rm -f data/input_line_tmp.txt\n",
    "\n",
    "# Write out last line of song to temp file\n",
    "tail --lines=1 data/song_from_scratch.txt > data/input_line_tmp.txt\n",
    "\n",
    "DATA_DIR=data/t2t_data\n",
    "OUTDIR=t2t_model_full2\n",
    "MODEL=transformer\n",
    "HPARAMS=transformer_lyric_generation\n",
    "\n",
    "# the file with the input lines\n",
    "DECODE_FILE=data/input_line_tmp.txt\n",
    "\n",
    "BEAM_SIZE=4\n",
    "ALPHA=0.6\n",
    "\n",
    "# Generate next line, write out to data/input_line_tmp.txt.*.decodes\n",
    "t2t-decoder \\\n",
    "  --data_dir=$DATA_DIR \\\n",
    "  --problem=$PROBLEM \\\n",
    "  --model=$MODEL \\\n",
    "  --hparams_set=transformer_lyric_generation \\\n",
    "  --output_dir=$OUTDIR \\\n",
    "  --t2t_usr_dir=lyric_generation/trainer \\\n",
    "  --decode_hparams=\"beam_size=$BEAM_SIZE,alpha=$ALPHA\" \\\n",
    "  --decode_from_file=$DECODE_FILE\n",
    "\n",
    "# Append generated line to song\n",
    "cat ${DECODE_FILE}.*.decodes >> data/song_from_scratch.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data science students got bars for days\n",
      "And I'm a lot of the same thing\n",
      "It's all about the same thing\n",
      "It's all about you\n",
      "It's all about you\n",
      "It's all about you\n",
      "It's all about you\n",
      "It's all about you\n",
      "It's all about you\n",
      "It's all about you\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Destroy temp file\n",
    "rm -f data/input_line_tmp.txt\n",
    "\n",
    "# Admire our handiwork\n",
    "cat data/song_from_scratch.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are still phrases and not complete sentences. This indicates that we might need to train longer or better somehow.\n",
    "\n",
    "Tensorboard shows the loss curves plateau fairly quickly, and stop improving. What we really need to do is to get more data, but if that's not an option, we could try to reduce the NN and increase the dropout regularization. We could also do hyperparameter tuning on the dropout and network sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
